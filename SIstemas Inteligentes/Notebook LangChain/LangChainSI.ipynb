{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b1941535-130c-40d2-9385-2e4c54f3dd82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- IMPORTS ----------\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import PyPDFLoader, TextLoader, WebBaseLoader, WikipediaLoader\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import HBox, VBox, Layout, Output, Button, Dropdown, Text, Textarea, IntSlider, FloatSlider, Checkbox, FileUpload\n",
    "from IPython.display import display, clear_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8078742e-67c3-4f48-bb06-a7bdf742bb5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPENAI_API_KEY: sk-pro\n",
      "GOOGLE_API_KEY: AIzaSy\n",
      "GROQ_API_KEY: gsk_KZ\n"
     ]
    }
   ],
   "source": [
    "# ---------- API KEYS ----------\n",
    "print(\"OPENAI_API_KEY:\", os.getenv(\"OPENAI_API_KEY\")[:6])\n",
    "print(\"GOOGLE_API_KEY:\", os.getenv(\"GOOGLE_API_KEY\")[:6])\n",
    "print(\"GROQ_API_KEY:\", os.getenv(\"GROQ_API_KEY\")[:6])\n",
    "\n",
    "# ---------- ESTADO GLOBAL ----------\n",
    "loaded_docs = []           # documentos cargados\n",
    "conversation_messages = [] # historial de conversación\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b6402621-d9c4-4dc9-9211-636cb5e6e656",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a621b6e99e446f18b2e14542e46626f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Proveedor', options=('openai', 'google', 'groq', 'ollama'), value='openai')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "457314bf681f4371b253dc4814fc0972",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Modelo', options=('gpt-4o-mini', 'gpt-4o', 'gpt-3.5-turbo'), value='gpt-4o-mini')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ---------- PROVEEDOR Y MODELOS DINÁMICOS ----------\n",
    "\n",
    "provider_dropdown = Dropdown(\n",
    "    options=[\"openai\", \"google\", \"groq\", \"ollama\"],\n",
    "    value=\"openai\",\n",
    "    description=\"Proveedor\"\n",
    ")\n",
    "\n",
    "model_dropdown = Dropdown(\n",
    "    options=[],\n",
    "    description=\"Modelo\"\n",
    ")\n",
    "\n",
    "# Modelos estáticos para APIs\n",
    "provider_models = {\n",
    "    \"openai\": [\"gpt-4o-mini\", \"gpt-4o\", \"gpt-3.5-turbo\"],\n",
    "    \"google\": [\"gemini-pro\", \"gemini-flash\"],\n",
    "    \"groq\": [\"mixtral-8x7b\", \"llama-3.1-8b\", \"groq/compound\"]\n",
    "}\n",
    "\n",
    "def list_ollama_models():\n",
    "    \"\"\"Devuelve lista de modelos locales instalados en Ollama.\"\"\"\n",
    "    try:\n",
    "        result = subprocess.run([\"ollama\", \"list\"], capture_output=True, text=True)\n",
    "        if result.returncode != 0:\n",
    "            return []\n",
    "        lines = result.stdout.strip().split(\"\\n\")[1:]  # saltar encabezado\n",
    "        models = [line.split()[0] for line in lines if line.strip()]\n",
    "        return models\n",
    "    except Exception:\n",
    "        return []\n",
    "\n",
    "def update_model_options(change):\n",
    "    provider = change['new']\n",
    "    if provider == \"ollama\":\n",
    "        local_models = list_ollama_models()\n",
    "        if not local_models:\n",
    "            model_dropdown.options = [\"<No hay modelos locales>\"]\n",
    "            model_dropdown.value = \"<No hay modelos locales>\"\n",
    "        else:\n",
    "            model_dropdown.options = local_models\n",
    "            model_dropdown.value = local_models[0]\n",
    "    else:\n",
    "        options = provider_models.get(provider, [])\n",
    "        if options:\n",
    "            model_dropdown.options = options\n",
    "            model_dropdown.value = options[0]\n",
    "        else:\n",
    "            model_dropdown.options = [\"<Sin modelos disponibles>\"]\n",
    "            model_dropdown.value = \"<Sin modelos disponibles>\"\n",
    "\n",
    "provider_dropdown.observe(update_model_options, names='value')\n",
    "update_model_options({'new': provider_dropdown.value})\n",
    "\n",
    "display(provider_dropdown, model_dropdown)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ae4b8b26-cc83-4169-b0e1-740850effd7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- PARÁMETROS DEL MODELO ----------\n",
    "temperature_slider = FloatSlider(value=0.7, min=0, max=1, step=0.05, description=\"Temp\")\n",
    "top_p_slider = FloatSlider(value=0.9, min=0, max=1, step=0.05, description=\"Top-p\")\n",
    "max_tokens_slider = IntSlider(value=512, min=64, max=4096, step=64, description=\"Tokens\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "eb2cf342-3580-4cec-9d82-ca0ab0880fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- WIDGETS DOCUMENTOS ----------\n",
    "file_uploader = FileUpload(accept=\".txt,.pdf\", multiple=True)\n",
    "wiki_query = Text(description=\"Wikipedia\")\n",
    "web_url = Text(description=\"Web URL\")\n",
    "\n",
    "chunk_size_slider = IntSlider(value=1000, min=200, max=4000, description=\"Chunk size\")\n",
    "chunk_overlap_slider = IntSlider(value=200, min=0, max=1000, description=\"Overlap\")\n",
    "summary_checkbox = Checkbox(value=False, description=\"Resumir docs\")\n",
    "\n",
    "doc_status = Output()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "44ea57a2-fbd1-49f0-a609-32007903f447",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- FUNCIONES DE DOCUMENTOS ----------\n",
    "def load_local():\n",
    "    global loaded_docs\n",
    "    if not file_uploader.value:\n",
    "        with doc_status:\n",
    "            clear_output()\n",
    "            print(\"Sube un archivo primero.\")\n",
    "        return\n",
    "\n",
    "    all_docs = []\n",
    "    for item in file_uploader.value:\n",
    "        fname = item['name']\n",
    "        content = item['content']\n",
    "        path = f\"/tmp/{fname}\"\n",
    "        with open(path, \"wb\") as f:\n",
    "            f.write(content)\n",
    "\n",
    "        if fname.lower().endswith(\".pdf\"):\n",
    "            loader = PyPDFLoader(path)\n",
    "        else:\n",
    "            loader = TextLoader(path, encoding=\"utf-8\")\n",
    "\n",
    "        docs = loader.load()\n",
    "        all_docs.extend(docs)\n",
    "\n",
    "    loaded_docs = all_docs\n",
    "    with doc_status:\n",
    "        clear_output()\n",
    "        print(f\"Archivo(s) cargado(s): {len(file_uploader.value)} | Fragmentos: {len(loaded_docs)}\")\n",
    "\n",
    "def load_wikipedia(query):\n",
    "    global loaded_docs\n",
    "    if not query.strip():\n",
    "        with doc_status:\n",
    "            clear_output()\n",
    "            print(\"Escribe un término para Wikipedia.\")\n",
    "        return\n",
    "    loader = WikipediaLoader(query=query, load_max_docs=2)\n",
    "    loaded_docs = loader.load()\n",
    "    with doc_status:\n",
    "        clear_output()\n",
    "        print(f\"Cargados {len(loaded_docs)} documentos desde Wikipedia.\")\n",
    "\n",
    "def load_web(url):\n",
    "    global loaded_docs\n",
    "    if not url.strip():\n",
    "        with doc_status:\n",
    "            clear_output()\n",
    "            print(\"Escribe una URL válida.\")\n",
    "        return\n",
    "    loader = WebBaseLoader(url)\n",
    "    loaded_docs = loader.load()\n",
    "    with doc_status:\n",
    "        clear_output()\n",
    "        print(f\"Cargado documento desde {url}.\")\n",
    "\n",
    "def process_docs():\n",
    "    global loaded_docs\n",
    "    if not loaded_docs:\n",
    "        with doc_status:\n",
    "            clear_output()\n",
    "            print(\"Primero carga un documento.\")\n",
    "        return\n",
    "\n",
    "    splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size_slider.value,\n",
    "        chunk_overlap=chunk_overlap_slider.value\n",
    "    )\n",
    "    docs = splitter.split_documents(loaded_docs)\n",
    "\n",
    "    if summary_checkbox.value:\n",
    "        try:\n",
    "            llm = get_model()\n",
    "            summaries = []\n",
    "            for d in docs[:5]:\n",
    "                resp = llm.invoke([HumanMessage(content=f\"Resume el siguiente texto:\\n\\n{d.page_content}\")])\n",
    "                summaries.append(Document(page_content=resp.content))\n",
    "            docs = summaries\n",
    "            msg = f\"Documentos resumidos a {len(docs)} fragmentos.\"\n",
    "        except Exception as e:\n",
    "            msg = f\"Error al resumir: {e}\"\n",
    "    else:\n",
    "        msg = f\"Documento dividido en {len(docs)} fragmentos.\"\n",
    "\n",
    "    loaded_docs = docs\n",
    "    with doc_status:\n",
    "        clear_output()\n",
    "        print(msg)\n",
    "\n",
    "def reset_docs():\n",
    "    global loaded_docs\n",
    "    loaded_docs = []\n",
    "    with doc_status:\n",
    "        clear_output()\n",
    "        print(\"Documentos limpiados.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c67e5e67-cebf-49fa-8196-4067049caa45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- CHAT Y MODELOS ----------\n",
    "def get_model():\n",
    "    provider = provider_dropdown.value\n",
    "    model = model_dropdown.value\n",
    "    temp = temperature_slider.value\n",
    "    top_p = top_p_slider.value\n",
    "    max_tokens = max_tokens_slider.value\n",
    "\n",
    "    if provider == \"openai\":\n",
    "        return ChatOpenAI(model=model, temperature=temp, max_tokens=max_tokens)\n",
    "    elif provider == \"google\":\n",
    "        return ChatGoogleGenerativeAI(model=model, temperature=temp)\n",
    "    elif provider == \"groq\":\n",
    "        return ChatGroq(model=model, temperature=temp, max_tokens=max_tokens)\n",
    "    elif provider == \"ollama\":\n",
    "        return ChatOllama(model=model)\n",
    "    else:\n",
    "        raise ValueError(\"Proveedor desconocido\")\n",
    "\n",
    "chat_input = Textarea(placeholder=\"Escribe tu mensaje...\", layout=Layout(width=\"600px\", height=\"100px\"))\n",
    "send_btn = Button(description=\"Enviar\", layout=Layout(width=\"120px\"))\n",
    "clear_btn = Button(description=\"Limpiar\", layout=Layout(width=\"120px\"))\n",
    "chat_out = Output()\n",
    "\n",
    "def on_send(_):\n",
    "    global conversation_messages, loaded_docs\n",
    "    user_msg = chat_input.value.strip()\n",
    "    if not user_msg:\n",
    "        return\n",
    "\n",
    "    # Añadir mensaje del usuario\n",
    "    conversation_messages.append(HumanMessage(content=user_msg))\n",
    "\n",
    "    llm = get_model()\n",
    "\n",
    "    # Agregar contexto si hay documentos cargados\n",
    "    context_text = \"\\n\\n\".join([d.page_content for d in loaded_docs[:3]]) if loaded_docs else \"\"\n",
    "    if context_text:\n",
    "        conversation_messages.insert(-1, SystemMessage(content=f\"Usa este contexto para responder:\\n{context_text}\"))\n",
    "\n",
    "    try:\n",
    "        resp = llm.invoke(conversation_messages)\n",
    "        conversation_messages.append(resp)\n",
    "        with chat_out:\n",
    "            print(f\"Usuario: {user_msg}\")\n",
    "            print(f\"Asistente: {resp.content}\\n\")\n",
    "    except Exception as e:\n",
    "        with chat_out:\n",
    "            print(\"Error en la llamada al modelo:\", str(e))\n",
    "\n",
    "def on_clear(_):\n",
    "    global conversation_messages\n",
    "    conversation_messages = []\n",
    "    with chat_out:\n",
    "        clear_output()\n",
    "        print(\"Historial limpiado.\")\n",
    "\n",
    "send_btn.on_click(on_send)\n",
    "clear_btn.on_click(on_clear)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "eac8e2c2-9294-4357-8284-a7c3de62a72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- BOTONES DOCUMENTOS ----------\n",
    "btn_load_file = Button(description=\"Cargar archivo\", layout=Layout(width=\"150px\"))\n",
    "btn_load_file.on_click(lambda _: load_local())\n",
    "\n",
    "btn_load_wiki = Button(description=\"Cargar Wikipedia\", layout=Layout(width=\"150px\"))\n",
    "btn_load_wiki.on_click(lambda _: load_wikipedia(wiki_query.value))\n",
    "\n",
    "btn_load_web = Button(description=\"Cargar Web\", layout=Layout(width=\"150px\"))\n",
    "btn_load_web.on_click(lambda _: load_web(web_url.value))\n",
    "\n",
    "btn_process = Button(description=\"Procesar documento\", layout=Layout(width=\"150px\"))\n",
    "btn_process.on_click(lambda _: process_docs())\n",
    "\n",
    "btn_cancel = Button(description=\"Cancelar\", layout=Layout(width=\"150px\"))\n",
    "btn_cancel.on_click(lambda _: reset_docs())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1ab04a67-5798-4ed1-8a65-f25890ab9911",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c99ee2bf65648db974b4fe1b9a9b08c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Dropdown(description='Proveedor', index=3, options=('openai', 'google', 'groq', 'ollama'), valu…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ---------- UI FINAL ----------\n",
    "ui = VBox([\n",
    "    provider_dropdown,\n",
    "    model_dropdown,\n",
    "    HBox([temperature_slider, top_p_slider, max_tokens_slider],\n",
    "         layout=Layout(justify_content=\"center\", align_items=\"center\")),\n",
    "\n",
    "    VBox([chat_input], layout=Layout(justify_content=\"center\", align_items=\"center\")),\n",
    "    HBox([send_btn, clear_btn], layout=Layout(justify_content=\"center\", align_items=\"center\")),\n",
    "\n",
    "    HBox([file_uploader, btn_load_file], layout=Layout(justify_content=\"center\", align_items=\"center\")),\n",
    "    HBox([wiki_query, btn_load_wiki], layout=Layout(justify_content=\"center\", align_items=\"center\")),\n",
    "    HBox([web_url, btn_load_web], layout=Layout(justify_content=\"center\", align_items=\"center\")),\n",
    "\n",
    "    HBox([chunk_size_slider, chunk_overlap_slider, summary_checkbox],\n",
    "         layout=Layout(justify_content=\"center\", align_items=\"center\")),\n",
    "    HBox([btn_process, btn_cancel], layout=Layout(justify_content=\"center\", align_items=\"center\")),\n",
    "\n",
    "    doc_status,\n",
    "    chat_out\n",
    "], layout=Layout(align_items=\"center\"))\n",
    "\n",
    "display(ui)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b8974d-4ad0-4f24-a120-a51dfa6727a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
