{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc36f561-1f9c-4675-8c90-116ada842e5f",
   "metadata": {},
   "source": [
    "# Conectar Langchain con con OpenAI\n",
    "\n",
    "### Pasos previos importantes:\n",
    "- Descargar LangChain desde la consola de Anaconda\n",
    "- `Pip install langchain`\n",
    "- Crear una cuenta en OpenIA\n",
    "- Obtener un key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ad32e822-8818-4d4b-929f-e9bafb092e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4dd643c-546b-45d0-a4cc-d009b0c7f4c8",
   "metadata": {},
   "source": [
    "## Mensajes en LangChain (`SystemMessage` y `HumanMessage`)\n",
    "\n",
    "En LangChain, la comunicación con los modelos de lenguaje (LLMs) se basa en un sistema de mensajes que permiten estructurar las interacciones en un formato comprensible tanto para el modelo como para el desarrollador. Dos de los mensajes principales utilizados son `SystemMessage` y `HumanMessage`. A continuación, se explica qué son y para qué sirven, junto con ejemplos prácticos.\n",
    "\n",
    "---\n",
    "### 1. HumanMessage\n",
    "El HumanMessage representa una intervención realizada por un usuario humano. Es el mensaje que usualmente inicia la conversación o una nueva instrucción. Se utiliza para formular preguntas, dar comandos o realizar solicitudes al modelo.\n",
    "\n",
    "Propósito:\n",
    "- Representa lo que el usuario desea comunicar al modelo.\n",
    "-  Es el input principal que desencadena una respuesta del modelo\n",
    "\n",
    "\n",
    "#### **Ejemplo de uso:**\n",
    "```python\n",
    "from langchain.schema import HumanMessage\n",
    "\n",
    "mensaje_usuario = HumanMessage(\n",
    "    content=\"¿Puedes explicarme cómo resolver una ecuación cuadrática paso a paso?\"\n",
    ")\n",
    "```\n",
    "\n",
    "### **2. `SystemMessage`**\n",
    "Un `SystemMessage` es un mensaje utilizado para definir el **contexto** o las **instrucciones iniciales** que guiarán al modelo durante toda la interacción. Se utiliza para establecer el comportamiento esperado del modelo o proporcionar un marco de trabajo para el resto de la conversación.\n",
    "\n",
    "#### **Propósito:**\n",
    "- Configurar el tono, los límites y las expectativas del modelo.\n",
    "- Asegurarse de que el modelo comprenda el propósito principal de la interacción.\n",
    "- Proveer instrucciones claras y precisas que influirán en cómo se interpretan y generan las respuestas.\n",
    "\n",
    "#### **Ejemplo de uso:**\n",
    "```python\n",
    "from langchain.schema import SystemMessage\n",
    "\n",
    "mensaje_sistema = SystemMessage(\n",
    "    content=\"Eres un asistente experto en matemáticas que ayuda a resolver problemas paso a paso.\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "15a7e993-c9d6-4802-a181-23d4543d3ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Importación de las librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "65d3b838-02e6-4abe-8e30-479b017a45b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.schema import SystemMessage, HumanMessage\n",
    "\n",
    "# Forma alternativa para importar los tipos de mensajes\n",
    "# from langchain_core.messages import SystemMessage, HumanMessage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd6eeaf-f879-4e05-8a11-346894027581",
   "metadata": {},
   "source": [
    "### Configuracion de la clave de acceso: key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "04c3fad5-223a-4379-895e-d763074a32d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Cargamos la api-key de open generada en platform de OpenAI\n",
    "f = open('key/key_prueba.txt')\n",
    "api_key = f.read()\n",
    "chat = ChatOpenAI(openai_api_key=api_key)  # Generamos una conexión al modelo de OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd6cec7-5036-461a-849e-dd7ebc0aa0b3",
   "metadata": {},
   "source": [
    "## Obtenter un resultado invocando al chat de OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a36bc66f-e88e-4846-9173-931930a0f85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se indica el prompt con el HumanMessage\n",
    "resultado = chat.invoke([HumanMessage(content= \"Indicame donde queda Pasto\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "df0a9b13-eec9-43e7-9c8b-18965772b512",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Pasto es una ciudad ubicada en el departamento de Nariño, en el suroeste de Colombia. Se encuentra a aproximadamente 800 kilómetros al suroeste de Bogotá.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 42, 'prompt_tokens': 14, 'total_tokens': 56, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-BfJWhdaW5lrsBss78KXDc7iDMKVJM', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--4bd7998c-7e97-46c6-ab0c-54ac0a570297-0', usage_metadata={'input_tokens': 14, 'output_tokens': 42, 'total_tokens': 56, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tenemos la respuesta, más otros datos\n",
    "resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fc4c6fe8-16bc-4173-aa6e-f0cf14f6c05f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Pasto es una ciudad ubicada en el departamento de Nariño, en el suroeste de Colombia. Se encuentra a aproximadamente 800 kilómetros al suroeste de Bogotá.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Nos quedamos solo con la respuesta limpia\n",
    "resultado.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0550e9d-ab0a-42b6-b1ea-c41effcdec07",
   "metadata": {},
   "source": [
    "## Especificando el SystemMessage\n",
    "\n",
    "Se especifica el systemMessage para definir la personalidad que debe tener el sistema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2d7c4c49-d212-48ff-9247-d470ebbf167d",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado =chat.invoke([SystemMessage(content=\"Eres un historiador y experto en las ciudades Latinoamericanas\"), HumanMessage(\"Indicame donde queda San Gil\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cce8aed2-0a90-4998-94bb-952ac7150a78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='San Gil es una ciudad ubicada en el departamento de Santander, en Colombia. Se encuentra en el centro del país, aproximadamente a 300 kilómetros al noreste de Bogotá, la capital de Colombia. San Gil es conocida por ser un destino turístico popular debido a sus paisajes naturales, actividades de aventura y deportes extremos, como el rafting, la escalada en roca, entre otros.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 93, 'prompt_tokens': 34, 'total_tokens': 127, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-BfJWnUypGNY2okCI6gg5kYDMUrDDn', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--83643e46-ff46-40a9-8057-e462e861be06-0', usage_metadata={'input_tokens': 34, 'output_tokens': 93, 'total_tokens': 127, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eef2c61e-5440-4dfd-a72c-1f7e32cc90e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'San Gil es una ciudad ubicada en el departamento de Santander, en Colombia. Se encuentra en el centro del país, aproximadamente a 300 kilómetros al noreste de Bogotá, la capital de Colombia. San Gil es conocida por ser un destino turístico popular debido a sus paisajes naturales, actividades de aventura y deportes extremos, como el rafting, la escalada en roca, entre otros.'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultado.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe29f576-253f-422c-8a9c-2374d1056a76",
   "metadata": {},
   "source": [
    "## Obteniendo varios resultados invocando al chat de OpenAI con \"generate\"\n",
    "\n",
    "Mediante el metodo 'generate', se pueden hacer llamadas por lotes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "284e10fb-8909-4bdd-91df-25414c5a6d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado = chat.generate(\n",
    "    [\n",
    "        [SystemMessage(content = 'Eres un historiador y experto en las ciudades Latinoamericanas'),\n",
    "         HumanMessage(content = 'Indicame donde queda Ocaña')],\n",
    "        [SystemMessage(content = 'Eres un joven rudo a quien no le gusta que le anden preguntando cosas, su único interés es salir de fiesta'),\n",
    "         HumanMessage(content = 'Indicame donde queda Cúcuta\"')]\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6b28fb4f-fe88-4f12-9f81-4491b33b2ef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Claro, Ocaña es una ciudad ubicada en el departamento de Norte de Santander, en Colombia. Se encuentra en el noreste del país, en la región conocida como la región del Catatumbo, cerca de la frontera con Venezuela. Ocaña es una ciudad con una rica historia colonial y un importante patrimonio arquitectónico.\n",
      "\n",
      " Lo siento, no puedo ayudarte con eso. ¡Lo siento, pero te puedo decir dónde pasan las mejores fiestas!\n"
     ]
    }
   ],
   "source": [
    "# Resultado con el primer prompt sistema\n",
    "print(resultado.generations[0][0].text)\n",
    "\n",
    "# Resultado con el segundo prompt del sistema\n",
    "print(\"\\n\",resultado.generations[1][0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d871f0b-78c6-413f-b6ca-d89f022aeca3",
   "metadata": {},
   "source": [
    "# Documentación: Plantillas de Prompt en LangChain\n",
    "\n",
    "En LangChain, las **plantillas de Prompt** son estructuras predefinidas que facilitan la creación de mensajes personalizados y reutilizables para interactuar con modelos de lenguaje. Estas plantillas son fundamentales para estructurar las interacciones, integrar variables dinámicas y garantizar consistencia en los mensajes enviados. nos permite enviar las solicitudes(mensajes) como parámetros para estandarizar el proceso y facilitar la interacción con otros componentes de mis aplicaciones.\n",
    "\n",
    "---\n",
    "\n",
    "## **¿Qué son las plantillas de Prompt y para qué sirven?**\n",
    "\n",
    "Una plantilla de Prompt permite definir mensajes que pueden incluir contenido estático (texto fijo) y dinámico (variables que cambian según el contexto). Estas plantillas son útiles para estandarizar las entradas al modelo, reducir la repetición manual y generar mensajes adaptables.\n",
    "\n",
    "### **Beneficios:**\n",
    "- **Automatización:** Evitan escribir mensajes repetitivos.\n",
    "- **Flexibilidad:** Incorporan variables dinámicas para personalizar la interacción.\n",
    "- **Estandarización:** Aseguran un formato consistente en los mensajes.\n",
    "\n",
    "---\n",
    "\n",
    "## **Clases principales de plantillas en LangChain**\n",
    "\n",
    "### **1. PromptTemplate**\n",
    "La clase básica para construir mensajes personalizados. Integra variables dinámicas y permite estructurar mensajes con contenido estático.\n",
    "\n",
    "#### **Propósito:**\n",
    "Generar mensajes base reutilizables que combinen texto fijo y valores dinámicos.\n",
    "\n",
    "#### **Ejemplo de uso:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cd7f4e87-094f-4580-bdb7-3ea78ed22610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hola, Juan. ¿Cómo puedo ayudarte hoy?\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"nombre\"],\n",
    "    template=\"Hola, {nombre}. ¿Cómo puedo ayudarte hoy?\"\n",
    ")\n",
    "\n",
    "mensaje = prompt.format(nombre=\"Juan\")\n",
    "print(mensaje)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630fa844-e62b-4ced-9306-7728cca17110",
   "metadata": {},
   "source": [
    "### **2. ChatPromptTemplate**\r\n",
    "\r\n",
    "`ChatPromptTemplate` es una plantilla diseñada para estructurar y organizar interacciones en el contexto de conversaciones con modelos de lenguaje. Permite combinar diferentes tipos de mensajes (como los mensajes del sistema, humanos y generados por IA) en un solo flujo coherente. \r\n",
    "\r\n",
    "Esta plantilla es útil cuando se necesita definir un diálogo que involucra múltiples etapas o participantes, ya que proporciona una estructura flexible para gestionar estas interacciones de manera ordenada. Además, facilita la personalización y reutilización de flujos conversacionales, adaptándose a las necesidades específicas de la aplicación.\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "### **3. SystemMessagePromptTemplate**\r\n",
    "\r\n",
    "`SystemMessagePromptTemplate` se utiliza para generar mensajes del sistema que establecen el contexto general o las instrucciones iniciales para el modelo. Estos mensajes son clave para definir el comportamiento esperado del modelo durante la interacción y garantizar que las respuestas estén alineadas con el propósito de la aplicación.\r\n",
    "\r\n",
    "Es especialmente útil para configurar el tono, las reglas o el enfoque que debe seguir el modelo en el manejo de las consultas, proporcionando un marco claro para la conversación.\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "### **4. HumanMessagePromptTemplate**\r\n",
    "\r\n",
    "`HumanMessagePromptTemplate` es una plantilla destinada a representar las entradas o consultas realizadas por un usuario humano en el contexto de la interacción con el modelo. Su objetivo es estandarizar y estructurar las preguntas o comentarios humanos para asegurar consistencia y claridad en el flujo de mensajes.\r\n",
    "\r\n",
    "Esta plantilla resulta adecuada para personalizar mensajes según las necesidades de la interacción, permitiendo incluir elementos dinámicos o específicos proporcionados por los usuarios.\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "### **5. AIMessagePromptTemplate**\r\n",
    "\r\n",
    "`AIMessagePromptTemplate` está diseñada para construir mensajes que simulan las respuestas generadas por la inteligencia artificial dentro de una conversación. Estos mensajes son útiles para predefinir o estandarizar cómo deben ser las respuestas de la IA en escenarios controlados o planificados.\r\n",
    "\r\n",
    "Esta plantilla permite que los desarrolladores ajusten la manera en que la IA responde en el contexto de flujos conversacionales, asegurando que los mensajes sean coherentes y alineados con el propósito del sistema.\r\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759b39d6-6a35-49e9-a03d-d2de432e4496",
   "metadata": {},
   "source": [
    "| **Plantilla**               | **Propósito**                                                                 | **Uso principal**                                                                                       |\r\n",
    "|-----------------------------|------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------|\r\n",
    "| **PromptTemplate**           | Genera mensajes básicos combinando texto estático y variables dinámicas.      | Crear prompts reutilizables y personalizables con contenido dinámico.                                 |\r\n",
    "| **ChatPromptTemplate**       | Estructura flujos conversacionales combinando mensajes de distintos tipos.    | Crear interacciones complejas y organizadas entre humanos, sistema e inteligencia artificial.         |\r\n",
    "| **SystemMessagePromptTemplate** | Define mensajes del sistema para establecer contexto y reglas iniciales.       | Configurar el comportamiento esperado del modelo durante la interacción.                              |\r\n",
    "| **HumanMessagePromptTemplate**  | Representa las consultas o entradas realizadas por un usuario humano.         | Estandarizar y personalizar preguntas o comentarios del usuario.                                      |\r\n",
    "| **AIMessagePromptTemplate**     | Construye mensajes que simulan respuestas generadas por la inteligencia artificial. | Predefinir y controlar las respuestas de la IA en flujos conversacionales planificados.               |\r\n",
    "             |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57356d0f-20fd-4d8f-bffa-e887c94b3f44",
   "metadata": {},
   "source": [
    "### Importar librerias para templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3da1ebef-6384-4dc9-a232-5c7a2e88cfef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    PromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    AIMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "\n",
    "from langchain.schema import (\n",
    "    AIMessage,\n",
    "    HumanMessage,\n",
    "    SystemMessage\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e706f5c6-1e78-4cbf-a1ad-677adf0eb8af",
   "metadata": {},
   "source": [
    "### Generar plantillas de prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec70362e-641f-49f4-8c1c-0b6d4c13234e",
   "metadata": {},
   "source": [
    "#### 1. Crear plantillas del sistema (system_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2e9186dc-4284-4e7b-aa7c-2894e7f715bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_template = \"Eres una IA especializada en automóviles de tipo {tipo_automovil} y en generar artículos que se leen en {tiempo_lectura}.\"\n",
    "system_message_prompt = SystemMessagePromptTemplate.from_template(system_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a2e38284-7ce0-41df-8f9f-9f7231b942e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tiempo_lectura', 'tipo_automovil']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_message_prompt.input_variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4c7444-6a6e-4686-a0ed-b9e9445ddcbf",
   "metadata": {},
   "source": [
    "#### 2. Crear la plantilla del usuario (human_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "51791452-27b6-41a8-8bb2-ec5e89b3a749",
   "metadata": {},
   "outputs": [],
   "source": [
    "human_template = \"Necesito un artículo para vehículos con motor {peticion_tipo_motor}\"\n",
    "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4fb8c253-1f51-40fd-b96e-83b8e838a2c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['peticion_tipo_motor']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "human_message_prompt.input_variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d8ecd7-6089-44a7-8726-ad965264672e",
   "metadata": {},
   "source": [
    "#### 3. Creamos una plantilla de chat con la concatenación tanto de mensajes del sistema como del humano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e9ef74c1-e465-49ef-8f6c-6ed012fa3326",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt,human_message_prompt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e4c0ffca-7cf8-450d-ad1d-c7ea96cb6f3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['peticion_tipo_motor', 'tiempo_lectura', 'tipo_automovil']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_prompt.input_variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac04222d-ab78-430e-8588-6a7e31282f84",
   "metadata": {},
   "source": [
    "#### 4. Completar el chat gracias al formateo de los mensajes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "926f8b76-d584-4251-978c-2028acb8dbd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='Eres una IA especializada en automóviles de tipo japonés y en generar artículos que se leen en 5 minutos.', additional_kwargs={}, response_metadata={}), HumanMessage(content='Necesito un artículo para vehículos con motor híbrido enchufable', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_prompt.format_prompt(peticion_tipo_motor = \"híbrido enchufable\",tiempo_lectura = \"5 minutos\", tipo_automovil = \"japonés\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d99b0b9-c97b-40af-ae10-51dc0afb2b73",
   "metadata": {},
   "source": [
    "#### 5. Se transforma el objeto prompt a una lista de mensajes y se guarda en una variable para enviar al LLM\n",
    "EL objeto prompt se guarda en la variables **solicitud_completa** que es la que se enviará finalmente al LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9d350598-004b-41c2-9d11-f6cbdba83232",
   "metadata": {},
   "outputs": [],
   "source": [
    "solicitud_completa = chat_prompt.format_prompt(peticion_tipo_motor = \"hibrido\",tiempo_lectura = \"3 minutos\", tipo_automovil = \"Europea\").to_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1d055bc9-91c3-40aa-ba15-5b4954ca0a25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='Eres una IA especializada en automóviles de tipo Europea y en generar artículos que se leen en 3 minutos.', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Necesito un artículo para vehículos con motor hibrido', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solicitud_completa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257d5b04-5d99-4bfe-8d33-a26f5e8fabf0",
   "metadata": {},
   "source": [
    "### Obtener el resultado de la respuesta formateada "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "21478396-5b77-448d-b1df-b6e4a39fe91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d935f4e8-8401-4b22-87e9-a2315a50f848",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Cargamos la api-key de open generada en platform de OpenAI\n",
    "f = open('key/key_prueba.txt')\n",
    "api_key = f.read()\n",
    "chat = ChatOpenAI(openai_api_key=api_key)  # Generamos una conexión al modelo de OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7d734255-4c82-4ea3-9573-4f5dbf66757e",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = chat.invoke(solicitud_completa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b85ffb46-d8ce-47b6-8aeb-e381b4736781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¡Claro! Aquí tienes un artículo sobre vehículos con motor híbrido:\n",
      "\n",
      "Los vehículos con motor híbrido son una opción cada vez más popular en el mercado automotriz, ya que combinan la eficiencia de un motor eléctrico con la potencia de un motor de combustión interna. Esta tecnología híbrida ofrece una serie de ventajas que la hacen atractiva tanto para los consumidores como para el medio ambiente.\n",
      "\n",
      "En primer lugar, los vehículos híbridos son más eficientes en cuanto al consumo de combustible. Al utilizar un motor eléctrico para mover el vehículo a velocidades bajas o en situaciones de tráfico denso, se reduce el consumo de combustible y, por lo tanto, las emisiones de gases contaminantes. Esto se traduce en un ahorro de dinero a largo plazo y en una menor huella ecológica.\n",
      "\n",
      "Además, la tecnología híbrida permite una conducción más silenciosa y suave, ya que el motor eléctrico produce menos ruido y vibraciones que un motor de combustión interna tradicional. Esto mejora la experiencia de conducción tanto para el conductor como para los pasajeros, haciendo que los viajes sean más agradables y confortables.\n",
      "\n",
      "Otra ventaja de los vehículos híbridos es su mayor autonomía, ya que al tener dos fuentes de energía disponibles (eléctrica y de combustión), se reducen las preocupaciones por la autonomía de la batería eléctrica. Esto hace que los vehículos híbridos sean una opción viable incluso para viajes largos o en zonas donde la infraestructura de recarga eléctrica es limitada.\n",
      "\n",
      "En cuanto al mantenimiento, los vehículos híbridos suelen requerir menos visitas al taller que los vehículos de combustión interna convencionales, ya que el desgaste de los componentes es menor gracias al uso alternado de los dos motores. Además, muchos fabricantes ofrecen garantías extendidas para los componentes eléctricos de los vehículos híbridos, lo que brinda una mayor tranquilidad al comprador.\n",
      "\n",
      "En resumen, los vehículos con motor híbrido ofrecen una combinación de eficiencia, rendimiento y tecnología que los convierte en una excelente opción para aquellos que buscan reducir su impacto ambiental y ahorrar en costos de combustible a largo plazo. Con una gama cada vez mayor de modelos disponibles en el mercado, los vehículos híbridos se posicionan como una alternativa atractiva y sostenible para el futuro de la movilidad.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96e9cda-d53d-4b48-bcd0-d0969ee770b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3fd5f33d-563d-49f1-b56c-0713f174efff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getenv(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34917cd2-72b0-4f8e-a30a-aadb790bb2b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54122b5e-7fb1-4c53-a910-b46c11654df8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092c0d90-c100-4c7e-a267-0daa20e6283d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
