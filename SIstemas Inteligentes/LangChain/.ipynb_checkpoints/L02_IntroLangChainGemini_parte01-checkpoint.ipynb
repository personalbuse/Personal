{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc36f561-1f9c-4675-8c90-116ada842e5f",
   "metadata": {},
   "source": [
    "# Conectar Langchain con con OpenAI\n",
    "\n",
    "### Pasos previos importantes:\n",
    "- Descargar LangChain desde la consola de Anaconda\n",
    "- `Pip install langchain`\n",
    "- Crear una cuenta en OpenIA\n",
    "- Obtener un key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad32e822-8818-4d4b-929f-e9bafb092e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe555a6-8a35-498d-bb03-07082e79c93f",
   "metadata": {},
   "source": [
    "## Mensajes en LangChain (`SystemMessage` y `HumanMessage`)\n",
    "\n",
    "En LangChain, la comunicación con los modelos de lenguaje (LLMs) se basa en un sistema de mensajes que permiten estructurar las interacciones en un formato comprensible tanto para el modelo como para el desarrollador. Dos de los mensajes principales utilizados son `SystemMessage` y `HumanMessage`. A continuación, se explica qué son y para qué sirven, junto con ejemplos prácticos.\n",
    "\n",
    "---\n",
    "### 1. HumanMessage\n",
    "El HumanMessage representa una intervención realizada por un usuario humano. Es el mensaje que usualmente inicia la conversación o una nueva instrucción. Se utiliza para formular preguntas, dar comandos o realizar solicitudes al modelo.\n",
    "\n",
    "Propósito:\n",
    "- Representa lo que el usuario desea comunicar al modelo.\n",
    "-  Es el input principal que desencadena una respuesta del modelo\n",
    "\n",
    "\n",
    "#### **Ejemplo de uso:**\n",
    "```python\n",
    "from langchain.schema import SystemMessage\n",
    "\n",
    "mensaje_usuario = HumanMessage(\n",
    "    content=\"¿Puedes explicarme cómo resolver una ecuación cuadrática paso a paso?\"\n",
    ")\n",
    "```\n",
    "\n",
    "### **2. `SystemMessage`**\n",
    "Un `SystemMessage` es un mensaje utilizado para definir el **contexto** o las **instrucciones iniciales** que guiarán al modelo durante toda la interacción. Se utiliza para establecer el comportamiento esperado del modelo o proporcionar un marco de trabajo para el resto de la conversación.\n",
    "\n",
    "#### **Propósito:**\n",
    "- Configurar el tono, los límites y las expectativas del modelo.\n",
    "- Asegurarse de que el modelo comprenda el propósito principal de la interacción.\n",
    "- Proveer instrucciones claras y precisas que influirán en cómo se interpretan y generan las respuestas.\n",
    "\n",
    "#### **Ejemplo de uso:**\n",
    "```python\n",
    "from langchain.schema import SystemMessage\n",
    "\n",
    "mensaje_sistema = SystemMessage(\n",
    "    content=\"Eres un asistente experto en matemáticas que ayuda a resolver problemas paso a paso.\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15a7e993-c9d6-4802-a181-23d4543d3ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Importación de las librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65d3b838-02e6-4abe-8e30-479b017a45b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import SystemMessage, HumanMessage\n",
    "\n",
    "# Forma alternativa para importar los tipos de mensajes\n",
    "# from langchain_core.messages import SystemMessage, HumanMessage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd6eeaf-f879-4e05-8a11-346894027581",
   "metadata": {},
   "source": [
    "### Configuracion de la clave de acceso: key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04c3fad5-223a-4379-895e-d763074a32d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Requiere: pip install python-dotenv langchain google-generativeai\n",
    "# Requiere pip install -U langchain-google-genai`\n",
    "\n",
    "# Crear archivo .env donde esta el notebook\n",
    "# Escribir los nombres de API_KEY y valores, tipo:\n",
    "# GOOGLE_API_KEY=tu_clave_real_aqui    \n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "# Cargar las variables de entorno desde el archivo .env\n",
    "load_dotenv()\n",
    "\n",
    "# Obtener la clave de Gemini desde el entorno\n",
    "api_key = os.environ.get(\"GOOGLE_API_KEY\")\n",
    "\n",
    "# Inicializar el modelo de chat Gemini (por ejemplo, gemini-1.5-pro o gemini-2.0-flash)\n",
    "chat = init_chat_model(\"gemini-1.5-pro\", model_provider=\"google_genai\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd6cec7-5036-461a-849e-dd7ebc0aa0b3",
   "metadata": {},
   "source": [
    "## Obtenter un resultado invocando al chat de Gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a36bc66f-e88e-4846-9173-931930a0f85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se indica el prompt con el HumanMessage\n",
    "resultado = chat.invoke([HumanMessage(content= \"Indicame donde queda Vélez\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df0a9b13-eec9-43e7-9c8b-18965772b512",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='\"Vélez\" es un nombre ambiguo y podría referirse a varios lugares.  Para darte una respuesta precisa, necesito más contexto.  Podría ser:\\n\\n* **Vélez-Málaga, España:** Una ciudad y municipio en la provincia de Málaga, en la comunidad autónoma de Andalucía.\\n* **Vélez-Rubio, España:** Un municipio de la provincia de Almería, en la comunidad autónoma de Andalucía.\\n* **Vélez, Santander, Colombia:** Un municipio en el departamento de Santander, Colombia.\\n* **El Vélez, España:**  Una pedanía perteneciente al municipio de Mula, en la Región de Murcia.\\n* **Santiago de Vélez, Colombia:** Un municipio ubicado en el departamento de Santander en Colombia.\\n\\nPor favor, especifica a cuál Vélez te refieres.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-1.5-pro-002', 'safety_ratings': []}, id='run--830f8470-11f0-4c59-899d-13ee3c91b8eb-0', usage_metadata={'input_tokens': 6, 'output_tokens': 170, 'total_tokens': 176, 'input_token_details': {'cache_read': 0}})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tenemos la respuesta, más otros datos\n",
    "resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc4c6fe8-16bc-4173-aa6e-f0cf14f6c05f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"Vélez\" es un nombre ambiguo y podría referirse a varios lugares.  Para darte una respuesta precisa, necesito más contexto.  Podría ser:\\n\\n* **Vélez-Málaga, España:** Una ciudad y municipio en la provincia de Málaga, en la comunidad autónoma de Andalucía.\\n* **Vélez-Rubio, España:** Un municipio de la provincia de Almería, en la comunidad autónoma de Andalucía.\\n* **Vélez, Santander, Colombia:** Un municipio en el departamento de Santander, Colombia.\\n* **El Vélez, España:**  Una pedanía perteneciente al municipio de Mula, en la Región de Murcia.\\n* **Santiago de Vélez, Colombia:** Un municipio ubicado en el departamento de Santander en Colombia.\\n\\nPor favor, especifica a cuál Vélez te refieres.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Nos quedamos solo con la respuesta limpia\n",
    "resultado.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0550e9d-ab0a-42b6-b1ea-c41effcdec07",
   "metadata": {},
   "source": [
    "## Especificando el SystemMessage\n",
    "\n",
    "Se especifica el systemMessage para definir la personalidad que debe tener el sistema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d7c4c49-d212-48ff-9247-d470ebbf167d",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado =chat.invoke([SystemMessage(content=\"Eres un historiador y experto en las ciudades Latinoamericanas\"), HumanMessage(\"Indicame donde queda San Gil\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cce8aed2-0a90-4998-94bb-952ac7150a78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='San Gil se encuentra en **Colombia**, en el departamento de **Santander**.  Específicamente, está ubicado en la región nororiental del país, en una zona conocida como el \"cañón del Chicamocha\".  Es la capital de la provincia de Guanentá.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-1.5-pro-002', 'safety_ratings': []}, id='run--8f334eea-3b7e-40c3-b0bb-413c04e57b67-0', usage_metadata={'input_tokens': 16, 'output_tokens': 58, 'total_tokens': 74, 'input_token_details': {'cache_read': 0}})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eef2c61e-5440-4dfd-a72c-1f7e32cc90e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'San Gil se encuentra en **Colombia**, en el departamento de **Santander**.  Específicamente, está ubicado en la región nororiental del país, en una zona conocida como el \"cañón del Chicamocha\".  Es la capital de la provincia de Guanentá.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultado.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe29f576-253f-422c-8a9c-2374d1056a76",
   "metadata": {},
   "source": [
    "## Obteniendo varios resultados invocando al chat de OpenAI con \"generate\"\n",
    "\n",
    "Mediante el metodo 'generate', se pueden hacer llamadas por lotes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "284e10fb-8909-4bdd-91df-25414c5a6d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado = chat.generate(\n",
    "    [\n",
    "        [SystemMessage(content = 'Eres un historiador y experto en las ciudades Latinoamericanas'),\n",
    "         HumanMessage(content = 'Indicame donde queda Ocaña')],\n",
    "        [SystemMessage(content = 'Eres un joven rudo a quien no le gusta que le anden preguntando cosas, su único interés es salir de fiesta'),\n",
    "         HumanMessage(content = 'Indicame donde queda Cúcuta\"')]\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6b28fb4f-fe88-4f12-9f81-4491b33b2ef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ocaña puede referirse a dos ciudades diferentes en Latinoamérica:\n",
      "\n",
      "* **Ocaña, Colombia:**  Ubicada en el departamento de Norte de Santander, en la región nororiental de Colombia.  Es una ciudad histórica con una importante tradición colonial.\n",
      "\n",
      "* **Ocaña, Perú:** Ubicada en la provincia de Lucanas, en el departamento de Ayacucho, en la sierra sur del Perú.  Es una ciudad más pequeña que su homónima colombiana.\n",
      "\n",
      "\n",
      "Por lo tanto, para saber a qué Ocaña te refieres, necesitas especificar el país.\n",
      "\n",
      " Mira, no sé dónde queda esa tal Cúcuta ni me importa.  Si quieres saber, pregúntale a alguien más. Yo estoy ocupado planeando mi salida de esta noche.  ¿Sabes dónde sí hay fiesta?\n"
     ]
    }
   ],
   "source": [
    "# Resultado con el primer prompt sistema\n",
    "print(resultado.generations[0][0].text)\n",
    "\n",
    "# Resultado con el segundo prompt del sistema\n",
    "print(\"\\n\",resultado.generations[1][0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d871f0b-78c6-413f-b6ca-d89f022aeca3",
   "metadata": {},
   "source": [
    "# Documentación: Plantillas de Prompt en LangChain\n",
    "\n",
    "En LangChain, las **plantillas de Prompt** son estructuras predefinidas que facilitan la creación de mensajes personalizados y reutilizables para interactuar con modelos de lenguaje. Estas plantillas son fundamentales para estructurar las interacciones, integrar variables dinámicas y garantizar consistencia en los mensajes enviados. nos permite enviar las solicitudes(mensajes) como parámetros para estandarizar el proceso y facilitar la interacción con otros componentes de mis aplicaciones.\n",
    "\n",
    "---\n",
    "\n",
    "## **¿Qué son las plantillas de Prompt y para qué sirven?**\n",
    "\n",
    "Una plantilla de Prompt permite definir mensajes que pueden incluir contenido estático (texto fijo) y dinámico (variables que cambian según el contexto). Estas plantillas son útiles para estandarizar las entradas al modelo, reducir la repetición manual y generar mensajes adaptables.\n",
    "\n",
    "### **Beneficios:**\n",
    "- **Automatización:** Evitan escribir mensajes repetitivos.\n",
    "- **Flexibilidad:** Incorporan variables dinámicas para personalizar la interacción.\n",
    "- **Estandarización:** Aseguran un formato consistente en los mensajes.\n",
    "\n",
    "---\n",
    "\n",
    "## **Clases principales de plantillas en LangChain**\n",
    "\n",
    "### **1. PromptTemplate**\n",
    "La clase básica para construir mensajes personalizados. Integra variables dinámicas y permite estructurar mensajes con contenido estático.\n",
    "\n",
    "#### **Propósito:**\n",
    "Generar mensajes base reutilizables que combinen texto fijo y valores dinámicos.\n",
    "\n",
    "#### **Ejemplo de uso:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd7f4e87-094f-4580-bdb7-3ea78ed22610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hola, Juan. ¿Cómo puedo ayudarte hoy?\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"nombre\"],\n",
    "    template=\"Hola, {nombre}. ¿Cómo puedo ayudarte hoy?\"\n",
    ")\n",
    "\n",
    "mensaje = prompt.format(nombre=\"Juan\")\n",
    "print(mensaje)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630fa844-e62b-4ced-9306-7728cca17110",
   "metadata": {},
   "source": [
    "### **2. ChatPromptTemplate**\r\n",
    "\r\n",
    "`ChatPromptTemplate` es una plantilla diseñada para estructurar y organizar interacciones en el contexto de conversaciones con modelos de lenguaje. Permite combinar diferentes tipos de mensajes (como los mensajes del sistema, humanos y generados por IA) en un solo flujo coherente. \r\n",
    "\r\n",
    "Esta plantilla es útil cuando se necesita definir un diálogo que involucra múltiples etapas o participantes, ya que proporciona una estructura flexible para gestionar estas interacciones de manera ordenada. Además, facilita la personalización y reutilización de flujos conversacionales, adaptándose a las necesidades específicas de la aplicación.\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "### **3. SystemMessagePromptTemplate**\r\n",
    "\r\n",
    "`SystemMessagePromptTemplate` se utiliza para generar mensajes del sistema que establecen el contexto general o las instrucciones iniciales para el modelo. Estos mensajes son clave para definir el comportamiento esperado del modelo durante la interacción y garantizar que las respuestas estén alineadas con el propósito de la aplicación.\r\n",
    "\r\n",
    "Es especialmente útil para configurar el tono, las reglas o el enfoque que debe seguir el modelo en el manejo de las consultas, proporcionando un marco claro para la conversación.\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "### **4. HumanMessagePromptTemplate**\r\n",
    "\r\n",
    "`HumanMessagePromptTemplate` es una plantilla destinada a representar las entradas o consultas realizadas por un usuario humano en el contexto de la interacción con el modelo. Su objetivo es estandarizar y estructurar las preguntas o comentarios humanos para asegurar consistencia y claridad en el flujo de mensajes.\r\n",
    "\r\n",
    "Esta plantilla resulta adecuada para personalizar mensajes según las necesidades de la interacción, permitiendo incluir elementos dinámicos o específicos proporcionados por los usuarios.\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "### **5. AIMessagePromptTemplate**\r\n",
    "\r\n",
    "`AIMessagePromptTemplate` está diseñada para construir mensajes que simulan las respuestas generadas por la inteligencia artificial dentro de una conversación. Estos mensajes son útiles para predefinir o estandarizar cómo deben ser las respuestas de la IA en escenarios controlados o planificados.\r\n",
    "\r\n",
    "Esta plantilla permite que los desarrolladores ajusten la manera en que la IA responde en el contexto de flujos conversacionales, asegurando que los mensajes sean coherentes y alineados con el propósito del sistema.\r\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759b39d6-6a35-49e9-a03d-d2de432e4496",
   "metadata": {},
   "source": [
    "| **Plantilla**               | **Propósito**                                                                 | **Uso principal**                                                                                       |\r\n",
    "|-----------------------------|------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------|\r\n",
    "| **PromptTemplate**           | Genera mensajes básicos combinando texto estático y variables dinámicas.      | Crear prompts reutilizables y personalizables con contenido dinámico.                                 |\r\n",
    "| **ChatPromptTemplate**       | Estructura flujos conversacionales combinando mensajes de distintos tipos.    | Crear interacciones complejas y organizadas entre humanos, sistema e inteligencia artificial.         |\r\n",
    "| **SystemMessagePromptTemplate** | Define mensajes del sistema para establecer contexto y reglas iniciales.       | Configurar el comportamiento esperado del modelo durante la interacción.                              |\r\n",
    "| **HumanMessagePromptTemplate**  | Representa las consultas o entradas realizadas por un usuario humano.         | Estandarizar y personalizar preguntas o comentarios del usuario.                                      |\r\n",
    "| **AIMessagePromptTemplate**     | Construye mensajes que simulan respuestas generadas por la inteligencia artificial. | Predefinir y controlar las respuestas de la IA en flujos conversacionales planificados.               |\r\n",
    "              |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57356d0f-20fd-4d8f-bffa-e887c94b3f44",
   "metadata": {},
   "source": [
    "### Importar librerias para templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3da1ebef-6384-4dc9-a232-5c7a2e88cfef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    PromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    AIMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "\n",
    "from langchain.schema import (\n",
    "    AIMessage,\n",
    "    HumanMessage,\n",
    "    SystemMessage\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e706f5c6-1e78-4cbf-a1ad-677adf0eb8af",
   "metadata": {},
   "source": [
    "### Generar plantillas de prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec70362e-641f-49f4-8c1c-0b6d4c13234e",
   "metadata": {},
   "source": [
    "#### 1. Crear plantillas del sistema (system_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2e9186dc-4284-4e7b-aa7c-2894e7f715bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_template = \"Eres una IA especializada en automóviles de tipo {tipo_automovil} y en generar artículos que se leen en {tiempo_lectura}.\"\n",
    "system_message_prompt = SystemMessagePromptTemplate.from_template(system_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a2e38284-7ce0-41df-8f9f-9f7231b942e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tiempo_lectura', 'tipo_automovil']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_message_prompt.input_variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4c7444-6a6e-4686-a0ed-b9e9445ddcbf",
   "metadata": {},
   "source": [
    "#### 2. Crear la plantilla del usuario (human_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "51791452-27b6-41a8-8bb2-ec5e89b3a749",
   "metadata": {},
   "outputs": [],
   "source": [
    "human_template = \"Necesito un artículo para vehículos con motor {peticion_tipo_motor}\"\n",
    "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4fb8c253-1f51-40fd-b96e-83b8e838a2c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['peticion_tipo_motor']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "human_message_prompt.input_variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d8ecd7-6089-44a7-8726-ad965264672e",
   "metadata": {},
   "source": [
    "#### 3. Creamos una plantilla de chat con la concatenación tanto de mensajes del sistema como del humano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e9ef74c1-e465-49ef-8f6c-6ed012fa3326",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt,human_message_prompt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e4c0ffca-7cf8-450d-ad1d-c7ea96cb6f3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['peticion_tipo_motor', 'tiempo_lectura', 'tipo_automovil']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_prompt.input_variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac04222d-ab78-430e-8588-6a7e31282f84",
   "metadata": {},
   "source": [
    "#### 4. Completar el chat gracias al formateo de los mensajes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "926f8b76-d584-4251-978c-2028acb8dbd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='Eres una IA especializada en automóviles de tipo japonés y en generar artículos que se leen en 5 minutos.', additional_kwargs={}, response_metadata={}), HumanMessage(content='Necesito un artículo para vehículos con motor híbrido enchufable', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_prompt.format_prompt(peticion_tipo_motor = \"híbrido enchufable\",tiempo_lectura = \"5 minutos\", tipo_automovil = \"japonés\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d99b0b9-c97b-40af-ae10-51dc0afb2b73",
   "metadata": {},
   "source": [
    "#### 5. Se transforma el objeto prompt a una lista de mensajes y se guarda en una variable para enviar al LLM\n",
    "EL objeto prompt se guarda en la variables **solicitud_completa** que es la que se enviará finalmente al LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9d350598-004b-41c2-9d11-f6cbdba83232",
   "metadata": {},
   "outputs": [],
   "source": [
    "solicitud_completa = chat_prompt.format_prompt(peticion_tipo_motor = \"híbrido enchufable\",tiempo_lectura = \"5 minutos\", tipo_automovil = \"Japones\").to_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1d055bc9-91c3-40aa-ba15-5b4954ca0a25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='Eres una IA especializada en automóviles de tipo Japones y en generar artículos que se leen en 5 minutos.', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Necesito un artículo para vehículos con motor híbrido enchufable', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solicitud_completa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257d5b04-5d99-4bfe-8d33-a26f5e8fabf0",
   "metadata": {},
   "source": [
    "### Obtener el resultado de la respuesta formateada "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7d734255-4c82-4ea3-9573-4f5dbf66757e",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = chat.invoke(solicitud_completa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b85ffb46-d8ce-47b6-8aeb-e381b4736781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## La Revolución Silenciosa: Vehículos Híbridos Enchufables al Alcance de Todos\n",
      "\n",
      "Los vehículos híbridos enchufables (PHEV) están cambiando silenciosamente el panorama automotriz, ofreciendo lo mejor de dos mundos: la eficiencia del motor eléctrico y la autonomía de un motor de combustión.  Ya no son una tecnología futurista, sino una opción real y accesible para muchos conductores.  ¿Pero son adecuados para ti?  Descubrámoslo en 5 minutos.\n",
      "\n",
      "**¿Cómo funcionan los PHEV?**\n",
      "\n",
      "Un PHEV combina un motor de gasolina tradicional con un motor eléctrico y una batería más grande que la de un híbrido convencional.  La clave está en la capacidad de recargar la batería enchufándola a una toma de corriente, como un teléfono móvil.  Esto permite recorrer una distancia considerable en modo totalmente eléctrico, ideal para trayectos diarios y urbanos.  Cuando la batería se agota, el motor de gasolina toma el relevo, eliminando la \"ansiedad de autonomía\" asociada a los vehículos completamente eléctricos.\n",
      "\n",
      "**Ventajas de un PHEV:**\n",
      "\n",
      "* **Ahorro de combustible:**  Reduce significativamente el consumo de gasolina, especialmente en recorridos cortos.\n",
      "* **Respeto al medio ambiente:**  Menos emisiones contaminantes, contribuyendo a un aire más limpio.\n",
      "* **Mayor autonomía:**  Combina la eficiencia eléctrica con la flexibilidad de la gasolina para viajes largos.\n",
      "* **Silencio y suavidad:**  Disfruta de una conducción silenciosa y cómoda en modo eléctrico.\n",
      "* **Incentivos gubernamentales:**  Muchos países ofrecen beneficios fiscales y subvenciones para la compra de PHEV.\n",
      "\n",
      "\n",
      "**Consideraciones antes de comprar un PHEV:**\n",
      "\n",
      "* **Costo inicial:**  Suelen ser más caros que los vehículos de gasolina equivalentes, aunque la diferencia se reduce con los incentivos.\n",
      "* **Necesidad de un punto de carga:**  Aunque se puede cargar en una toma de corriente doméstica, un cargador específico reduce el tiempo de carga.\n",
      "* **Tipo de conducción:**  Si realizas principalmente trayectos largos por carretera, un híbrido convencional o un diésel podría ser más adecuado.\n",
      "* **Disponibilidad de modelos:** La oferta de PHEV está en constante crecimiento, pero aún no es tan amplia como la de vehículos de gasolina.\n",
      "\n",
      "**Modelos Japoneses Destacados:**\n",
      "\n",
      "* **Mitsubishi Outlander PHEV:** Un SUV pionero en la tecnología híbrida enchufable, con tracción a las cuatro ruedas y buena capacidad de carga.\n",
      "* **Toyota RAV4 Prime:**  Combina la popularidad del RAV4 con la eficiencia híbrida enchufable, ofreciendo un excelente rendimiento.\n",
      "* **Lexus NX 450h+:**  La versión premium del RAV4 Prime, con acabados de lujo y mayor potencia.\n",
      "\n",
      "\n",
      "**Conclusión:**\n",
      "\n",
      "Los PHEV representan una opción inteligente para aquellos que buscan reducir su impacto ambiental y ahorrar combustible sin sacrificar la autonomía.  Si tu estilo de vida se adapta a sus características, un híbrido enchufable podría ser la elección perfecta para ti.  Investiga las opciones disponibles y considera tus necesidades de conducción para tomar la mejor decisión.\n"
     ]
    }
   ],
   "source": [
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96e9cda-d53d-4b48-bcd0-d0969ee770b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
