{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f97b7bc1-8ef1-487a-8889-c07e1d6bda2c",
   "metadata": {},
   "source": [
    "# Introducción a los Agentes en LangChain\n",
    "\n",
    "LangChain ha introducido un concepto innovador y poderoso para las aplicaciones basadas en modelos de lenguaje de gran escala (LLM): los agentes. Estas herramientas representan una extensión natural de las capacidades de los LLM al permitirles interactuar dinámicamente con diferentes herramientas y recursos externos, lo que los hace ideales para resolver tareas complejas.\n",
    "\n",
    "## ¿Qué son los Agentes en LangChain?\n",
    "\n",
    "Un agente en LangChain es un sistema que utiliza un modelo de lenguaje para:\n",
    "- **Seleccionar herramientas adecuadas**: Los agentes pueden determinar qué herramientas o fuentes de datos son necesarias para resolver una tarea específica.\n",
    "- **Integrar resultados**: Al conectarse con herramientas externas como motores de búsqueda, calculadoras o bases de datos, pueden usar los resultados obtenidos para avanzar hacia una solución.\n",
    "- **Seguir procesos estructurados**: Basados en el enfoque **ReAct** (Razonamiento y Acción), los agentes combinan razonamiento lógico con ejecución de acciones para manejar tareas que requieren múltiples pasos.\n",
    "\n",
    "## Características Clave de los Agentes\n",
    "\n",
    "- **Conexión con herramientas externas**: Los agentes pueden integrarse con recursos como APIs, documentos internos, bases de datos corporativas o herramientas personalizadas.\n",
    "- **Capacidad de razonamiento**: Siguiendo el enfoque ReAct, un agente puede analizar una tarea, tomar decisiones sobre los pasos a seguir y ejecutar acciones basadas en observaciones.\n",
    "- **Personalización**: Los agentes pueden ser configurados para trabajar con herramientas específicas según las necesidades de la aplicación.\n",
    "\n",
    "## Ventajas de Usar Agentes en LangChain\n",
    "\n",
    "- **Automatización avanzada**: Facilitan la creación de soluciones complejas que requieren integración de datos externos e internos.\n",
    "- **Escalabilidad**: Los agentes son lo suficientemente flexibles para adaptarse a diversas áreas, desde asistentes corporativos hasta sistemas de soporte técnico.\n",
    "- **Desempeño mejorado**: Al conectar datos relevantes y ejecutar acciones en tiempo real, los agentes pueden proporcionar respuestas precisas y bien fundamentadas.\n",
    "\n",
    "## Ejemplo de Aplicación\n",
    "\n",
    "Imagina un agente diseñado para una empresa que:\n",
    "1. **Accede a documentos corporativos internos**: Permite consultar información sobre políticas, manuales o datos específicos.\n",
    "2. **Realiza búsquedas externas**: Puede obtener datos actualizados de fuentes confiables como noticias o publicaciones especializadas.\n",
    "3. **Integra las respuestas**: Responde preguntas de empleados o clientes combinando información interna y externa, mejorando la productividad y la satisfacción.\n",
    "\n",
    "\n",
    "Los agentes en LangChain son una herramienta clave para llevar las capacidades de los LLM a otro nivel, permitiendo desarrollar aplicaciones más robustas y adaptadas a las necesidades específicas de cada contexto. Con su capacidad de razonar, actuar y conectar herramientas, los agentes representan un paso adelante en el diseño de aplicaciones inteligentes.\n",
    "\n",
    "![Agentes en acción](imgs/agents.gif)\n",
    "\n",
    "# ¿Qué es el patrón ReAct?\n",
    "\n",
    "ReAct (abreviatura de Reasoning and Acting) es un paradigma para el diseño de agentes de IA en el que un agente utiliza el razonamiento en cadena de pensamiento y las acciones de uso de herramientas en agregación.\n",
    "\n",
    "En lugar de generar una respuesta directa en un solo paso, un agente de ReAct piensa paso a paso y puede realizar acciones intermedias (como buscar algo o calcular un valor) antes de finalizar su respuesta.\n",
    "\n",
    "![Gráfico comparativo](imgs/comparativo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce525b94-08ae-45a5-8e59-1920fc28101d",
   "metadata": {},
   "source": [
    "## Ejemplo práctico 1: Un agente simple:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f819720f-698e-4d99-9c00-427ad6a3b99c",
   "metadata": {},
   "source": [
    "- Cargamos las librerías necesarias e inicializamos el LLM.\n",
    "- Es recomendable asignar el parámetro *temperatura* a 0 para que el LLM no sea muy creativo ya que se van a tener muchas herramientas a nuestra disposición y queremos que sea más determinista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1d043000-793c-4648-83b2-64675a46ed50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate, SystemMessagePromptTemplate, ChatPromptTemplate, HumanMessagePromptTemplate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1fac0759-6c7e-4489-87b9-e5a8802a418f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hola! Como soy una inteligencia artificial, no tengo sentimientos o emociones como los seres humanos, por lo que no estoy realmente \"bien\" o \"mal\". Sin embargo, estoy funcionando correctamente y lista para ayudarte en lo que necesites.\n",
      "\n",
      "En cuanto a quién soy, soy LLaMA, una inteligencia artificial desarrollada por Meta AI que puede entender y responder a preguntas, generar texto, traducir idiomas, y mucho más. Mi capacidad para procesar y analizar grandes cantidades de datos me permite proporcionar respuestas precisas y relevantes a tus preguntas. ¡Estoy aquí para ayudarte!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "# Cargar la API key desde .env\n",
    "load_dotenv(override=True)\n",
    "\n",
    "# Crear conexión con Groq\n",
    "llm = ChatGroq(\n",
    "    model=\"llama3-70b-8192\",   # También puedes usar \"mixtral-8x7b-32768\"\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "# Probar conexión\n",
    "respuesta = llm.invoke(\"Hola, ¿cómo estás?, ¿quién eres?\")\n",
    "print(respuesta.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d718c973-078f-4ef7-b6ad-f69e2239d896",
   "metadata": {},
   "source": [
    "- Se importan las clases para usar los agentes:\n",
    "\n",
    "### `load_tools`\r\n",
    "Función para cargar herramientas predefinidas o personalizadas que los agentes pueden usar, como calculadoras, motores de búsqueda o APIs.\r\n",
    "\r\n",
    "### `initialize_agent`\r\n",
    "Configura un agente combinando un modelo de lenguaje (LLM), herramientas y un tipo de agente, ajustando su comportamiento para resolver tareas específicas.\r\n",
    "\r\n",
    "### `AgentType`\r\n",
    "Enumeración que define los diferentes tipos de agentes disponibles, como reactivos o conversacionales, permitiendo seleccionar el enfoque más adecuado.\r\n",
    "\r\n",
    "### `create_react_agent`\r\n",
    "Función que crea un agente basado en el marco ReAct, combinando razonamiento y acciones para resolver tareas de múltiples pasos.\r\n",
    "\r\n",
    "### `AgentExecutor`\r\n",
    "Clase que ejecuta las tareas del agente, gestionando el uso de herramientas y devolviendo resultados tras completar los objetivos.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "13978673-1db8-41a6-8b7b-b1e89cb973f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import (load_tools,\n",
    "                            initialize_agent,\n",
    "                            AgentType,\n",
    "                            create_react_agent,\n",
    "                            AgentExecutor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca94f8a2-effa-4d65-9827-47262a625b6c",
   "metadata": {},
   "source": [
    "- Ahora se definen las herramientas a las cuales tendrá acceso el angente, a parte del propio LLM. Podemos ver un listado de tales herramientas en el siguiente enlace:  https://python.langchain.com/docs/integrations/tools/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e84538b5-d49e-4665-b716-62450e470fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para usa esta Tool, es posible que debas instalar por consola:  pip install numexpr\n",
    "tools = load_tools([\"llm-math\",],llm=llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f26b52-a292-4de9-b6c5-1a303b7b3b06",
   "metadata": {},
   "source": [
    "- Se pueden ver todos los agentes disponibles para usar con la siguiente linea de código:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c84b8374-2624-40bb-a974-206055034cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dir(AgentType) #Vemos los diferentes tipos de agente a usar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0fc02b6-c207-41c2-a4d7-60cca8cda3f1",
   "metadata": {},
   "source": [
    "- Describirmos brevemente aqui cada tipo:\n",
    "\n",
    "### `CHAT_CONVERSATIONAL_REACT_DESCRIPTION`\n",
    "Agente para interacciones conversacionales, combina razonamiento y respuestas basadas en el contexto del chat.\n",
    "\n",
    "### `CHAT_ZERO_SHOT_REACT_DESCRIPTION`\n",
    "Similar al anterior, pero actúa sin ejemplos previos, tomando decisiones en tiempo real.\n",
    "\n",
    "### `CONVERSATIONAL_REACT_DESCRIPTION`\n",
    "Enfocado en conversaciones, utiliza razonamiento y herramientas externas para responder con precisión.\n",
    "\n",
    "### `OPENAI_FUNCTIONS`\n",
    "Agente que utiliza funciones específicas de OpenAI para manejar tareas definidas por la API.\n",
    "\n",
    "### `OPENAI_MULTI_FUNCTIONS`\n",
    "Extensión del anterior, soporta múltiples funciones de OpenAI para tareas más complejas.\n",
    "\n",
    "### `REACT_DOCSTORE`\n",
    "Agente diseñado para buscar y extraer información en bases de datos documentales.\n",
    "\n",
    "### `SELF_ASK_WITH_SEARCH`\n",
    "Agente que formula preguntas a sí mismo y utiliza herramientas de búsqueda para encontrar respuestas.\n",
    "\n",
    "### `STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION`\n",
    "Agente conversacional que sigue un enfoque estructurado para tareas sin ejemplos previos.\n",
    "\n",
    "### `ZERO_SHOT_REACT_DESCRIPTION`\n",
    "Agente genérico que resuelve tareas en tiempo real, razonando y actuando sin datos de entrenamiento específicos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e796ea6f-8819-427d-b3d2-b5fb6ff4bc70",
   "metadata": {},
   "source": [
    "- Ahora se puede inicializar el agente y posteriormente incializar.\n",
    "\n",
    "***Tener en cuenta que es una versión que está en transcición y será obsoleta en futuras versiones. Estable hasta el momento.***\n",
    "\n",
    "- Se utiliza el Zero Shot porque no estamos dando ningún ejemplo, solo pidiendo al agente hacer una tarea sin ejemplos previos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8b15b324-ade8-4b4a-8dca-ca011a2fd78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,verbose=True,handle_parsing_errors=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888b63b1-b18f-4db9-8067-987f681a17f0",
   "metadata": {},
   "source": [
    "- Ahora realizamos la solicitud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "75770558-44fb-4943-96dd-84d3d20fe853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I need to perform a multiplication and then an addition to get the final answer.\n",
      "\n",
      "Action: Calculator\n",
      "Action Input: 2345 * 5431\u001b[0m"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "unknown format from LLM: Here is the translation:\n\n```text\n2345 * 5431\n```\n...numexpr.evaluate(\"2345 * 5431\")...",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[32]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m agent.invoke(\u001b[33m\"\u001b[39m\u001b[33mCuánto es 2345 multiplicado por 5431 y después sumado 1234\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniconda3\\envs\\lang-env\\Lib\\site-packages\\langchain\\chains\\base.py:165\u001b[39m, in \u001b[36mChain.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    162\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    163\u001b[39m     \u001b[38;5;28mself\u001b[39m._validate_inputs(inputs)\n\u001b[32m    164\u001b[39m     outputs = (\n\u001b[32m--> \u001b[39m\u001b[32m165\u001b[39m         \u001b[38;5;28mself\u001b[39m._call(inputs, run_manager=run_manager)\n\u001b[32m    166\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[32m    167\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call(inputs)\n\u001b[32m    168\u001b[39m     )\n\u001b[32m    170\u001b[39m     final_outputs: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] = \u001b[38;5;28mself\u001b[39m.prep_outputs(\n\u001b[32m    171\u001b[39m         inputs,\n\u001b[32m    172\u001b[39m         outputs,\n\u001b[32m    173\u001b[39m         return_only_outputs,\n\u001b[32m    174\u001b[39m     )\n\u001b[32m    175\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniconda3\\envs\\lang-env\\Lib\\site-packages\\langchain\\agents\\agent.py:1625\u001b[39m, in \u001b[36mAgentExecutor._call\u001b[39m\u001b[34m(self, inputs, run_manager)\u001b[39m\n\u001b[32m   1623\u001b[39m \u001b[38;5;66;03m# We now enter the agent loop (until it returns something).\u001b[39;00m\n\u001b[32m   1624\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m._should_continue(iterations, time_elapsed):\n\u001b[32m-> \u001b[39m\u001b[32m1625\u001b[39m     next_step_output = \u001b[38;5;28mself\u001b[39m._take_next_step(\n\u001b[32m   1626\u001b[39m         name_to_tool_map,\n\u001b[32m   1627\u001b[39m         color_mapping,\n\u001b[32m   1628\u001b[39m         inputs,\n\u001b[32m   1629\u001b[39m         intermediate_steps,\n\u001b[32m   1630\u001b[39m         run_manager=run_manager,\n\u001b[32m   1631\u001b[39m     )\n\u001b[32m   1632\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(next_step_output, AgentFinish):\n\u001b[32m   1633\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._return(\n\u001b[32m   1634\u001b[39m             next_step_output,\n\u001b[32m   1635\u001b[39m             intermediate_steps,\n\u001b[32m   1636\u001b[39m             run_manager=run_manager,\n\u001b[32m   1637\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniconda3\\envs\\lang-env\\Lib\\site-packages\\langchain\\agents\\agent.py:1325\u001b[39m, in \u001b[36mAgentExecutor._take_next_step\u001b[39m\u001b[34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[39m\n\u001b[32m   1316\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_take_next_step\u001b[39m(\n\u001b[32m   1317\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1318\u001b[39m     name_to_tool_map: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, BaseTool],\n\u001b[32m   (...)\u001b[39m\u001b[32m   1322\u001b[39m     run_manager: Optional[CallbackManagerForChainRun] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1323\u001b[39m ) -> Union[AgentFinish, \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mtuple\u001b[39m[AgentAction, \u001b[38;5;28mstr\u001b[39m]]]:\n\u001b[32m   1324\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._consume_next_step(\n\u001b[32m-> \u001b[39m\u001b[32m1325\u001b[39m         \u001b[38;5;28mlist\u001b[39m(\n\u001b[32m   1326\u001b[39m             \u001b[38;5;28mself\u001b[39m._iter_next_step(\n\u001b[32m   1327\u001b[39m                 name_to_tool_map,\n\u001b[32m   1328\u001b[39m                 color_mapping,\n\u001b[32m   1329\u001b[39m                 inputs,\n\u001b[32m   1330\u001b[39m                 intermediate_steps,\n\u001b[32m   1331\u001b[39m                 run_manager,\n\u001b[32m   1332\u001b[39m             ),\n\u001b[32m   1333\u001b[39m         ),\n\u001b[32m   1334\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniconda3\\envs\\lang-env\\Lib\\site-packages\\langchain\\agents\\agent.py:1408\u001b[39m, in \u001b[36mAgentExecutor._iter_next_step\u001b[39m\u001b[34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[39m\n\u001b[32m   1406\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m agent_action\n\u001b[32m   1407\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m agent_action \u001b[38;5;129;01min\u001b[39;00m actions:\n\u001b[32m-> \u001b[39m\u001b[32m1408\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mself\u001b[39m._perform_agent_action(\n\u001b[32m   1409\u001b[39m         name_to_tool_map,\n\u001b[32m   1410\u001b[39m         color_mapping,\n\u001b[32m   1411\u001b[39m         agent_action,\n\u001b[32m   1412\u001b[39m         run_manager,\n\u001b[32m   1413\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniconda3\\envs\\lang-env\\Lib\\site-packages\\langchain\\agents\\agent.py:1433\u001b[39m, in \u001b[36mAgentExecutor._perform_agent_action\u001b[39m\u001b[34m(self, name_to_tool_map, color_mapping, agent_action, run_manager)\u001b[39m\n\u001b[32m   1431\u001b[39m         tool_run_kwargs[\u001b[33m\"\u001b[39m\u001b[33mllm_prefix\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1432\u001b[39m     \u001b[38;5;66;03m# We then call the tool on the tool input to get an observation\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1433\u001b[39m     observation = tool.run(\n\u001b[32m   1434\u001b[39m         agent_action.tool_input,\n\u001b[32m   1435\u001b[39m         verbose=\u001b[38;5;28mself\u001b[39m.verbose,\n\u001b[32m   1436\u001b[39m         color=color,\n\u001b[32m   1437\u001b[39m         callbacks=run_manager.get_child() \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1438\u001b[39m         **tool_run_kwargs,\n\u001b[32m   1439\u001b[39m     )\n\u001b[32m   1440\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1441\u001b[39m     tool_run_kwargs = \u001b[38;5;28mself\u001b[39m._action_agent.tool_run_logging_kwargs()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniconda3\\envs\\lang-env\\Lib\\site-packages\\langchain_core\\tools\\base.py:888\u001b[39m, in \u001b[36mBaseTool.run\u001b[39m\u001b[34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, run_name, run_id, config, tool_call_id, **kwargs)\u001b[39m\n\u001b[32m    886\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m error_to_raise:\n\u001b[32m    887\u001b[39m     run_manager.on_tool_error(error_to_raise)\n\u001b[32m--> \u001b[39m\u001b[32m888\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m error_to_raise\n\u001b[32m    889\u001b[39m output = _format_output(content, artifact, tool_call_id, \u001b[38;5;28mself\u001b[39m.name, status)\n\u001b[32m    890\u001b[39m run_manager.on_tool_end(output, color=color, name=\u001b[38;5;28mself\u001b[39m.name, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniconda3\\envs\\lang-env\\Lib\\site-packages\\langchain_core\\tools\\base.py:857\u001b[39m, in \u001b[36mBaseTool.run\u001b[39m\u001b[34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, run_name, run_id, config, tool_call_id, **kwargs)\u001b[39m\n\u001b[32m    855\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m config_param := _get_runnable_config_param(\u001b[38;5;28mself\u001b[39m._run):\n\u001b[32m    856\u001b[39m         tool_kwargs |= {config_param: config}\n\u001b[32m--> \u001b[39m\u001b[32m857\u001b[39m     response = context.run(\u001b[38;5;28mself\u001b[39m._run, *tool_args, **tool_kwargs)\n\u001b[32m    858\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.response_format == \u001b[33m\"\u001b[39m\u001b[33mcontent_and_artifact\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    859\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(response) != \u001b[32m2\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniconda3\\envs\\lang-env\\Lib\\site-packages\\langchain_core\\tools\\simple.py:105\u001b[39m, in \u001b[36mTool._run\u001b[39m\u001b[34m(self, config, run_manager, *args, **kwargs)\u001b[39m\n\u001b[32m    103\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m config_param := _get_runnable_config_param(\u001b[38;5;28mself\u001b[39m.func):\n\u001b[32m    104\u001b[39m         kwargs[config_param] = config\n\u001b[32m--> \u001b[39m\u001b[32m105\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.func(*args, **kwargs)\n\u001b[32m    106\u001b[39m msg = \u001b[33m\"\u001b[39m\u001b[33mTool does not support sync invocation.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    107\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(msg)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniconda3\\envs\\lang-env\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:190\u001b[39m, in \u001b[36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    188\u001b[39m     warned = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    189\u001b[39m     emit_warning()\n\u001b[32m--> \u001b[39m\u001b[32m190\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m wrapped(*args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniconda3\\envs\\lang-env\\Lib\\site-packages\\langchain\\chains\\base.py:627\u001b[39m, in \u001b[36mChain.run\u001b[39m\u001b[34m(self, callbacks, tags, metadata, *args, **kwargs)\u001b[39m\n\u001b[32m    625\u001b[39m         msg = \u001b[33m\"\u001b[39m\u001b[33m`run` supports only one positional argument.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    626\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[32m--> \u001b[39m\u001b[32m627\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m(args[\u001b[32m0\u001b[39m], callbacks=callbacks, tags=tags, metadata=metadata)[\n\u001b[32m    628\u001b[39m         _output_key\n\u001b[32m    629\u001b[39m     ]\n\u001b[32m    631\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args:\n\u001b[32m    632\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m(kwargs, callbacks=callbacks, tags=tags, metadata=metadata)[\n\u001b[32m    633\u001b[39m         _output_key\n\u001b[32m    634\u001b[39m     ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniconda3\\envs\\lang-env\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:190\u001b[39m, in \u001b[36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    188\u001b[39m     warned = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    189\u001b[39m     emit_warning()\n\u001b[32m--> \u001b[39m\u001b[32m190\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m wrapped(*args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniconda3\\envs\\lang-env\\Lib\\site-packages\\langchain\\chains\\base.py:410\u001b[39m, in \u001b[36mChain.__call__\u001b[39m\u001b[34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[39m\n\u001b[32m    378\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Execute the chain.\u001b[39;00m\n\u001b[32m    379\u001b[39m \n\u001b[32m    380\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    401\u001b[39m \u001b[33;03m        `Chain.output_keys`.\u001b[39;00m\n\u001b[32m    402\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    403\u001b[39m config = {\n\u001b[32m    404\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mcallbacks\u001b[39m\u001b[33m\"\u001b[39m: callbacks,\n\u001b[32m    405\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtags\u001b[39m\u001b[33m\"\u001b[39m: tags,\n\u001b[32m    406\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m: metadata,\n\u001b[32m    407\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mrun_name\u001b[39m\u001b[33m\"\u001b[39m: run_name,\n\u001b[32m    408\u001b[39m }\n\u001b[32m--> \u001b[39m\u001b[32m410\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.invoke(\n\u001b[32m    411\u001b[39m     inputs,\n\u001b[32m    412\u001b[39m     cast(RunnableConfig, {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m config.items() \u001b[38;5;28;01mif\u001b[39;00m v \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m}),\n\u001b[32m    413\u001b[39m     return_only_outputs=return_only_outputs,\n\u001b[32m    414\u001b[39m     include_run_info=include_run_info,\n\u001b[32m    415\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniconda3\\envs\\lang-env\\Lib\\site-packages\\langchain\\chains\\base.py:165\u001b[39m, in \u001b[36mChain.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    162\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    163\u001b[39m     \u001b[38;5;28mself\u001b[39m._validate_inputs(inputs)\n\u001b[32m    164\u001b[39m     outputs = (\n\u001b[32m--> \u001b[39m\u001b[32m165\u001b[39m         \u001b[38;5;28mself\u001b[39m._call(inputs, run_manager=run_manager)\n\u001b[32m    166\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[32m    167\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call(inputs)\n\u001b[32m    168\u001b[39m     )\n\u001b[32m    170\u001b[39m     final_outputs: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] = \u001b[38;5;28mself\u001b[39m.prep_outputs(\n\u001b[32m    171\u001b[39m         inputs,\n\u001b[32m    172\u001b[39m         outputs,\n\u001b[32m    173\u001b[39m         return_only_outputs,\n\u001b[32m    174\u001b[39m     )\n\u001b[32m    175\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniconda3\\envs\\lang-env\\Lib\\site-packages\\langchain\\chains\\llm_math\\base.py:283\u001b[39m, in \u001b[36mLLMMathChain._call\u001b[39m\u001b[34m(self, inputs, run_manager)\u001b[39m\n\u001b[32m    277\u001b[39m _run_manager.on_text(inputs[\u001b[38;5;28mself\u001b[39m.input_key])\n\u001b[32m    278\u001b[39m llm_output = \u001b[38;5;28mself\u001b[39m.llm_chain.predict(\n\u001b[32m    279\u001b[39m     question=inputs[\u001b[38;5;28mself\u001b[39m.input_key],\n\u001b[32m    280\u001b[39m     stop=[\u001b[33m\"\u001b[39m\u001b[33m```output\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m    281\u001b[39m     callbacks=_run_manager.get_child(),\n\u001b[32m    282\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m283\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._process_llm_result(llm_output, _run_manager)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniconda3\\envs\\lang-env\\Lib\\site-packages\\langchain\\chains\\llm_math\\base.py:245\u001b[39m, in \u001b[36mLLMMathChain._process_llm_result\u001b[39m\u001b[34m(self, llm_output, run_manager)\u001b[39m\n\u001b[32m    243\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    244\u001b[39m     msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33munknown format from LLM: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mllm_output\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m245\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[32m    246\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;28mself\u001b[39m.output_key: answer}\n",
      "\u001b[31mValueError\u001b[39m: unknown format from LLM: Here is the translation:\n\n```text\n2345 * 5431\n```\n...numexpr.evaluate(\"2345 * 5431\")..."
     ]
    }
   ],
   "source": [
    "agent.invoke(\"Cuánto es 2345 multiplicado por 5431 y después sumado 1234\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73ca7f2-fccd-4424-9622-6402ab689459",
   "metadata": {},
   "source": [
    "- Qué pasa si solo se lo pregunto al LLM ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f0615993-afb4-4e72-ae2a-f2701509be83",
   "metadata": {},
   "outputs": [],
   "source": [
    "respuesta = llm.invoke(\"Cuánto es 2345 multiplicado por 5431 y después sumado 1234\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3c398b8b-63ec-4e2d-ac37-be2fbc2399c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vamos a realizar la operación paso a paso:\n",
      "\n",
      "1. Primero, multiplicamos 2345 por 5431:\n",
      "\n",
      "2345 × 5431 = 12,734,995\n",
      "\n",
      "2. Luego, sumamos 1234 al resultado:\n",
      "\n",
      "12,734,995 + 1234 = 12,736,229\n",
      "\n",
      "¡Eso es el resultado!\n"
     ]
    }
   ],
   "source": [
    "print(respuesta.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35bbf002-44f6-4070-8b98-709d85bf29e3",
   "metadata": {},
   "source": [
    "## Ejemplo 2: Consulta a motores de búsqueda\n",
    "\n",
    "- En este ejemplo se realiza va a utilizar una Tools llamada SerpApi, la cual da acceso a múltiples motores de búsqueda, por ahora en forma gratuita.\n",
    "- Para utilizarla se debe crear una cuenta y obtener un \"ApiKey\" en forma similar como se hizo con OpenAI.\n",
    "- Se puede crear la cuenta en la siguiente URL: https://serpapi.com/\n",
    "- Se debe instalar por consola: *pip install google-search-results*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0ae486-2b7c-4378-85fb-aec999c3c222",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6ac9c2-42a0-4924-9623-46e2e348bb44",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('key/key_serpapi.txt')\n",
    "serp_api_key = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13136c46-4d98-4551-9401-0215cc3b9ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definir variable de entorno para que funcione correctamente:\n",
    "import os\n",
    "os.environ[\"SERPAPI_API_KEY\"]=serp_api_key #Si no está definida el error nos dará el nombre de la variable de entorno que espera"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63200ed-7bb1-4e9d-a555-51fd543fc3a5",
   "metadata": {},
   "source": [
    "- Se definen las herramientas a las que tendrá acceso el agente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb1472b-b622-4a62-812a-c37124c7a79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = load_tools([\"serpapi\",\"llm-math\",],llm=llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79922b8-2031-4167-b61a-701065c2567d",
   "metadata": {},
   "source": [
    "- Se inicializa el agente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c4db10-4e47-4bf9-a972-f49690525c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e623d53-0b07-4abb-b733-c94ba1104844",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(os.getenv(\"SERPAPI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b03d7e-6859-45f2-b20b-af4823013f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.invoke(\"¿En qué año nació Einstein? ¿Cuál es el resultado de ese año multiplicado por 3?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45092b10-4e4b-427e-a40f-95b42fe23fc5",
   "metadata": {},
   "source": [
    "## Ejemplo 3. Un agente programador"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4782125-3fac-4f13-b06d-849fc3755e40",
   "metadata": {},
   "source": [
    "- En este ejemplo se utiliza una Tool especializada en generar código."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea5e39a-e19e-4be4-a4bc-65e55a2ee5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librerías requeridas\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate, SystemMessagePromptTemplate,ChatPromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain.agents import load_tools,initialize_agent,AgentType,create_react_agent,AgentExecutor\n",
    "f = open('key/key_prueba.txt')\n",
    "api_key = f.read()\n",
    "llm = ChatOpenAI(openai_api_key=api_key,temperature=0) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32da9985-ffda-4fe3-81ea-9f22c74c3cec",
   "metadata": {},
   "source": [
    "- Las clases requeridas para este ejemmplo particular:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c23855-334f-467c-9d1c-7f8a416570c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# puede requerir instalar desde consola: pip install langchain_experimental\n",
    "from langchain_experimental.agents.agent_toolkits import create_python_agent\n",
    "from langchain_experimental.tools.python.tool import PythonREPLTool\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a107a4-7ae9-4399-9790-5f4bc980a686",
   "metadata": {},
   "source": [
    "- `create_python_agent` Es una función de utilidad de LangChain que crea y configura un agente basado en lenguaje natural, capaz de usar herramientas para ejecutar código Python y razonar sobre los resultados.``\n",
    "- `PythonREPLTool` Es una herramienta (Tool) de LangChain que permite ejecutar código Python en un entorno REPL (Read-Eval-Print Loop)\n",
    "   - Toma un fragmento de código Python como entrada.\n",
    "   - Lo evalúa dentro de un entorno controlado.\n",
    "   - Devuelve el resultado o la salida como texto.\n",
    "   - Es útil para cálculos matemáticos, manipulación de listas, funciones, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8cfd6e9-6fcc-450e-bf4f-83f80946f067",
   "metadata": {},
   "source": [
    "- se crea el agente para crear y ejecutar código Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2cf1494-6f41-41fb-8c85-2b15fd36f2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_python_agent(tool=PythonREPLTool(),\n",
    "                           llm=llm,\n",
    "                           agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1080c226-71a3-43a5-be46-a75178f34d04",
   "metadata": {},
   "source": [
    "- Ejemplo de aplicacíón. Ordenar una lista dada:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55736a7d-0acc-4ed3-a52a-9df3ba2be309",
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_ejemplo = [3,1,5,3,5,6,7,3,5,10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57fd40a4-3962-46be-a408-6bd8b1db7e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.invoke('Ordena la lista dada {lista_ejemplo}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c453079c-013a-44da-b861-a2337235b1dc",
   "metadata": {},
   "source": [
    "### Un ejemplo sobre un conjunto de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b53e416-ee03-456f-8434-90c7da85cbf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6435b631-1e57-44cb-9edd-a6563b5e9330",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Datos/Datos_Empleados.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982f2c5d-c786-44ee-bc58-534921901038",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b851749-78e7-4b87-848c-58c45137d04e",
   "metadata": {},
   "source": [
    "- Se solicita que genere el çodigo para resolver un problema. Vamos a pedir que indique el código, más no que lo ejecute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96284f24-97b4-4a45-bd72-7f88a5026a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = agent.invoke(f'''¿Qué sentencias de código tendría que ejecutar para obtener la suma de salario total agregada por Nivel? Este sería el dataframe {df}, no tienes que ejecutar la sentencia, solo pasarme el código a ejecutar''')\n",
    "#agent.invoke(f'''¿Qué sentencias de código tendría que ejecutar para obtener la suma de salario total agregada por Nivel? Este sería el dataframe {df}, no tienes que ejecutar la sentencia, solo pasarme el código a ejecutar''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50d850f-73f6-4e6d-b08c-873684d14eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "res['output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab1157c-38c5-40cc-8d15-1f45bd199872",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('Nivel')['Salario'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0761c65e-888d-4f0e-8616-35f2414d51f3",
   "metadata": {},
   "source": [
    "- Ahra pidamos que ejecute la consulta:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1128df2-74bd-4a18-b9a3-6c01c45415b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.invoke(f'''¿Cuál es la suma agregada del salario total por nivel para el Nivel \"Semi-Senior\"? Este sería el dataframe {df}''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6bced6-4338-4aaa-9987-9f4b34af64ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = agent.invoke(f'''Escribe las líneas de código, sin ejecutarlo!! que tendría que ejecutar para obtener la suma de salario total agregada por Nivel. Este sería el dataframe {df}, ''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3502fa62-0818-42ce-ad9e-32338b32d2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "res['output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac3b1cf-1742-4486-ab1c-7ea53c46a8d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02527b3-fab2-41a9-9312-105d6a2da86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Puede requerir instalar por consola:  pip install seaborn\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8082e7-9629-4703-832f-b07cdfd06320",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.invoke(f'''¿Qué sentencias de código tendría que ejecutar para tener una visualización con la librería Seaborn que permita visualizar la suma agregada del Salario por Nivel? Este sería el dataframe {df}, recuerda que no tienes que ejecutar la sentencia, solo pasarme el código a ejecutar''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff57dd71-ff23-42ca-9156-3d7fb94ce8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x='Nivel', y='Salario', data=df, estimator=sum)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c9bde3-9011-4f16-bb6a-ad1956f9b66a",
   "metadata": {},
   "source": [
    "Tengo un DataFrame de pandas con información de salarios. Tiene dos columnas relevantes: `Nivel` (que representa el nivel jerárquico de un empleado, como Junior, Semi-Senior, Senior) y `Salario` (que indica el salario del empleado). Necesito que generes el código en Python para usar la librería Seaborn y crear una gráfica que muestre el salario total agrupado por `Nivel`. La gráfica debe ser un gráfico de barras donde el eje X sea el `Nivel` y el eje Y el salario total. Por favor, asegúrate de agregar títulos y etiquetas a los ejes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0133bde3-060e-466d-b0d0-33bb27bdd408",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Necesito que generes el código en Python para usar la librería Seaborn y crear una gráfica que muestre el salario total agrupado por Nivel en el data frame. Este es el data frame {df}. Solo genera el código, no lo ejecutes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259e5a4c-2cf6-4133-a906-2eeffc3af1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.invoke(f''+prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0218ba-46a7-4300-b7e9-b31c3a6bfe09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a03d2112-78a3-40b3-ab7b-90484bbcb798",
   "metadata": {},
   "source": [
    "## Ejemplo 4. Agente con Tool personalizada"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a18f2b-96d6-4b0b-95f8-f88bfc3b65fb",
   "metadata": {},
   "source": [
    "- Es posible desarrollar nuestras propias Tools, para resolver problemas específicos, con software propio o de la empresa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07fa657-ab74-48b8-8028-7657306417fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importemos las librerias para el ejemplo\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate, SystemMessagePromptTemplate,ChatPromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain.agents import load_tools,initialize_agent,AgentType,create_react_agent,AgentExecutor\n",
    "f = open('key/key_prueba.txt')\n",
    "api_key = f.read()\n",
    "llm = ChatOpenAI(openai_api_key=api_key,temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a387d235-2715-4529-a108-9a1a99d4c7bc",
   "metadata": {},
   "source": [
    "### Un ejemplo sencillo, una herramienta propia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9215fad6-9a73-4297-8c4a-a7d5f17a4ace",
   "metadata": {},
   "source": [
    "- Se requiere importar la siguiente liberia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95eb0854-ff38-416c-9cd3-64fa7274eca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1e1951-b888-4347-be27-be25acfb5c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def persona_amable (text: str) -> str:\n",
    "    '''Retorna la persona más amable. Se espera que la entrada esté vacía \"\" \n",
    "    y retorna la persona más amable del universo'''\n",
    "    return \"Pepito Pérez\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17fc833e-9fde-4d30-8b7a-6256bbf16e3f",
   "metadata": {},
   "source": [
    "- Que pasa si invocamos al agente sin indicarle la tool especializada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a9ad49-bc1c-48bb-87a7-9f4a71ed7e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = load_tools([\"wikipedia\",\"llm-math\",],llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef11eb6-9197-4384-a495-ff91f259b7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e86520-5d21-4a45-bde4-4cc17faddbd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.invoke(\"¿Quién es la persona más amable del universo?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e25ffde-3a1d-4bb6-811d-89bf746c3db2",
   "metadata": {},
   "source": [
    "### Ejecutar el ejemplo utilizando la nueva tool personalizada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962b8e0c-74ab-43af-87d6-c5b4bfc40c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = tools + [persona_amable]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25cf059-7596-402b-841f-18e971619a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a22496b-729e-4e2c-b57f-1d3d971d10cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = agent.invoke(\"¿Quién es la persona más amable del universo?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e829b5fb-89c9-4a7e-a2f3-defc69678e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result['output'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39dbd07-d67c-431f-bd3b-e06a97dbaf84",
   "metadata": {},
   "source": [
    "### Una plantilla para una API interna\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70aa3ff3-db1e-49eb-93ec-8f2a9fadbff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def nombre_api_interna(text: str) -> str:\n",
    "    '''Conecta a la API_xx que realiza la tarea xx, debes usar esta API Key'''\n",
    "    ##Definir conexión a la API interna y devolver un resultado\n",
    "    return resultado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d5bccd-0883-462d-b484-1dba156abcbf",
   "metadata": {},
   "source": [
    "### Y si tratamos de consultar la hora actual al agente?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2439b740-3dee-433d-b19b-c0253a070f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solicitud con las herramientas actuales no proporciona el resultado que queremos\n",
    "agent.invoke(\"¿Cuál es la hora actual?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8f722a-fc9f-465b-bd88-661751e40f8e",
   "metadata": {},
   "source": [
    "### Tool personalizada para obtener la hora actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d53408-44c3-4b26-90ad-e2ff801cf331",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372053f3-3cf5-4367-b07a-d3abb4e6aef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def hora_actual(text: str)->str:\n",
    "    '''Retorna la hora actual, debes usar esta función para cualquier consulta sobre la hora actual. Para fechas que no sean\n",
    "    la hora actual, debes usar otra herramienta. La entrada está vacía y la salida retorna una string'''\n",
    "    return str(datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37691edc-7cfc-4082-a2b5-1adc7d041548",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = tools + [hora_actual]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863efd79-d467-4da7-9dcc-136a9d4cb6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a557d42b-2a79-4eba-9de5-ed6b17eac9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solicitud con las herramientas actuales SÍ proporciona el resultado que queremos\n",
    "resultado = agent.invoke(\"¿Cuál es la hora actual?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57e8391-f183-4b17-946b-58766f27cb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado['output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10576b8b-29b3-4e5a-b396-b9af5a0c9e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.invoke(\"¿Cuál es la hora actual?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e68c0e-6f44-4724-93a6-705702276b6d",
   "metadata": {},
   "source": [
    "## Ejemplo 5. Agentes con memoria"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82346ddc-c28c-40cd-b82f-09cc4c9d1a32",
   "metadata": {},
   "source": [
    "- En este ejemplo se revisa como se incorpora la memoria en una aplicación conversacional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04b4926-cbfd-4379-b8cb-7d517b54aee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se importan las liberias respectivas\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate, SystemMessagePromptTemplate,ChatPromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain.agents import load_tools,initialize_agent,AgentType,create_react_agent,AgentExecutor\n",
    "f = open('key/key_prueba.txt')\n",
    "api_key = f.read()\n",
    "llm = ChatOpenAI(openai_api_key=api_key,temperature=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374318fb-5c40-4694-b4cd-a1c252423d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604cd7b1-00d0-4360-92e3-8e0be632cfe4",
   "metadata": {},
   "source": [
    "- En este caso de pone una clave o etiqueta a la memoria: *\"chat_history\"*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4d6186-27c5-4fa3-a4fe-5236b1cfd55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory(memory_key=\"chat_history\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3e87fe-b106-4cef-85e5-a0c0fb594b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = load_tools([\"wikipedia\",\"llm-math\",],llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3029a8f3-0b22-4ec6-8ffd-e9292c871563",
   "metadata": {},
   "outputs": [],
   "source": [
    "# agent = initialize_agent(tools, llm, agent=AgentType.CONVERSATIONAL_REACT_DESCRIPTION,memory=memory,verbose=True)\n",
    "\n",
    "agent = initialize_agent(\n",
    "    tools,\n",
    "    llm,\n",
    "    agent=AgentType.CONVERSATIONAL_REACT_DESCRIPTION,\n",
    "    memory=memory,\n",
    "    verbose=True,\n",
    "    handle_parsing_errors=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b812e12d-b1df-41dc-b859-0e12cc34e8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.invoke(\"Dime 5 productos esenciales para el mantenimiento del vehículo.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47fb5c1a-a932-493f-9162-b24e4e91ad06",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.invoke(\"¿Cuál de los anteriores es el más importante?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0893a0-13ed-4291-9357-e941487effd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.invoke(\"Necesito la respuesta anterior en español\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a73926-f84c-4a1b-ba6d-618d08cfae51",
   "metadata": {},
   "source": [
    "## Ejemplo 6. El agente consulta una base de datos vectorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224dbe60-cf8c-4545-bf59-a11b183d0662",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liberias relacionadas\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate, SystemMessagePromptTemplate,ChatPromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain.agents import load_tools,initialize_agent,AgentType,create_react_agent,AgentExecutor\n",
    "f = open('key/key_prueba.txt')\n",
    "api_key = f.read()\n",
    "llm = ChatOpenAI(openai_api_key=api_key,temperature=0) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7dd9a4-6f1a-4a6f-965a-12f267c8ae6d",
   "metadata": {},
   "source": [
    "- Se debe cargar la base de datos vectorial y el compresor, como en los ejemplos anteriores. Tambien se va añadir memoria al agente.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d530157-72a3-4c7e-865e-d94d84cdb97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bddd346-7f57-4c58-a7ee-4c38a2f14704",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import SKLearnVectorStore\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import LLMChainExtractor\n",
    "\n",
    "funcion_embedding = OpenAIEmbeddings(openai_api_key=api_key)\n",
    "persist_path=\"ejemploEmbeddingDB\"\n",
    "vector_store_connection = SKLearnVectorStore(embedding=funcion_embedding, persist_path=persist_path, serializer=\"parquet\")\n",
    "compressor = LLMChainExtractor.from_llm(llm)\n",
    "compression_retriever = ContextualCompressionRetriever(base_compressor=compressor, base_retriever=vector_store_connection.as_retriever())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c3bcb1-8c74-49ac-8f10-aa3f544d32ee",
   "metadata": {},
   "source": [
    "- A partir de la base de datos vectorial se construye la nueva tool, para obtener resultados optimos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44eed811-698b-434e-b3e6-0236580d33c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30dc3e8f-b9b8-4742-942c-fb65813e38d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def consulta_interna(text: str) -> str:\n",
    "    '''Retorna respuestas sobre el Reglamento Académico de Pregrado de la Universidad de Pamplona. \n",
    "    Se espera que la entrada sea una cadena de texto y retorna una cadena con el resultado más relevante. \n",
    "    Si la respuesta con esta herramienta es relevante, \n",
    "    no debes usar ninguna herramienta más ni tu propio conocimiento como LLM.'''\n",
    "    compressed_docs = compression_retriever.invoke(text)\n",
    "    \n",
    "    if not compressed_docs:\n",
    "        return \"No se encontró información relevante sobre esa consulta en el reglamento académico.\"\n",
    "    \n",
    "    resultado = compressed_docs[0].page_content\n",
    "    return resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc75d9e-db28-49c6-b08a-35bcd5ab8cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = load_tools([\"wikipedia\",\"llm-math\"],llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4c3f80-dbf6-4a8d-8a3e-7f4ae4715d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools=tools+[consulta_interna]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a15b25-7697-4dc0-b638-c11926c78e34",
   "metadata": {},
   "source": [
    "- Ahora se crea y ejecuta el agente conversacional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300cd887-d1b0-4baa-8d0b-5da5ab01d88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = initialize_agent(tools, llm, agent=AgentType.CONVERSATIONAL_REACT_DESCRIPTION,memory=memory,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f74d58-141f-499d-8918-d62a6e5914e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.invoke(\"¿Qué universidades existen en Norte de Santander, Colombia? Responde en español\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15e5fdd-de3b-4eba-9aee-e2cbbac3f76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.invoke(\"¿Cuáles son los requisitos de admisión para la Universidad de Pamplona?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30cbb9ef-44d4-4925-82ab-513d6003f1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.invoke(\"¿Cómo puedo cancelar materias en dicha universidad?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b008fd0-fd69-48ba-bd54-1b72db086067",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11f9ca1-353a-48b3-8a70-1c12ffb600fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (lang-env)",
   "language": "python",
   "name": "lang-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
