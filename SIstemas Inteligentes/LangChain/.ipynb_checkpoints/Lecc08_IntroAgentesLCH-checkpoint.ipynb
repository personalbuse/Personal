{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f97b7bc1-8ef1-487a-8889-c07e1d6bda2c",
   "metadata": {},
   "source": [
    "# Introducción a los Agentes en LangChain\n",
    "\n",
    "LangChain ha introducido un concepto innovador y poderoso para las aplicaciones basadas en modelos de lenguaje de gran escala (LLM): los agentes. Estas herramientas representan una extensión natural de las capacidades de los LLM al permitirles interactuar dinámicamente con diferentes herramientas y recursos externos, lo que los hace ideales para resolver tareas complejas.\n",
    "\n",
    "## ¿Qué son los Agentes en LangChain?\n",
    "\n",
    "Un agente en LangChain es un sistema que utiliza un modelo de lenguaje para:\n",
    "- **Seleccionar herramientas adecuadas**: Los agentes pueden determinar qué herramientas o fuentes de datos son necesarias para resolver una tarea específica.\n",
    "- **Integrar resultados**: Al conectarse con herramientas externas como motores de búsqueda, calculadoras o bases de datos, pueden usar los resultados obtenidos para avanzar hacia una solución.\n",
    "- **Seguir procesos estructurados**: Basados en el enfoque **ReAct** (Razonamiento y Acción), los agentes combinan razonamiento lógico con ejecución de acciones para manejar tareas que requieren múltiples pasos.\n",
    "\n",
    "## Características Clave de los Agentes\n",
    "\n",
    "- **Conexión con herramientas externas**: Los agentes pueden integrarse con recursos como APIs, documentos internos, bases de datos corporativas o herramientas personalizadas.\n",
    "- **Capacidad de razonamiento**: Siguiendo el enfoque ReAct, un agente puede analizar una tarea, tomar decisiones sobre los pasos a seguir y ejecutar acciones basadas en observaciones.\n",
    "- **Personalización**: Los agentes pueden ser configurados para trabajar con herramientas específicas según las necesidades de la aplicación.\n",
    "\n",
    "## Ventajas de Usar Agentes en LangChain\n",
    "\n",
    "- **Automatización avanzada**: Facilitan la creación de soluciones complejas que requieren integración de datos externos e internos.\n",
    "- **Escalabilidad**: Los agentes son lo suficientemente flexibles para adaptarse a diversas áreas, desde asistentes corporativos hasta sistemas de soporte técnico.\n",
    "- **Desempeño mejorado**: Al conectar datos relevantes y ejecutar acciones en tiempo real, los agentes pueden proporcionar respuestas precisas y bien fundamentadas.\n",
    "\n",
    "## Ejemplo de Aplicación\n",
    "\n",
    "Imagina un agente diseñado para una empresa que:\n",
    "1. **Accede a documentos corporativos internos**: Permite consultar información sobre políticas, manuales o datos específicos.\n",
    "2. **Realiza búsquedas externas**: Puede obtener datos actualizados de fuentes confiables como noticias o publicaciones especializadas.\n",
    "3. **Integra las respuestas**: Responde preguntas de empleados o clientes combinando información interna y externa, mejorando la productividad y la satisfacción.\n",
    "\n",
    "\n",
    "Los agentes en LangChain son una herramienta clave para llevar las capacidades de los LLM a otro nivel, permitiendo desarrollar aplicaciones más robustas y adaptadas a las necesidades específicas de cada contexto. Con su capacidad de razonar, actuar y conectar herramientas, los agentes representan un paso adelante en el diseño de aplicaciones inteligentes.\n",
    "\n",
    "![Agentes en acción](imgs/agents.gif)\n",
    "\n",
    "# ¿Qué es el patrón ReAct?\n",
    "\n",
    "ReAct (abreviatura de Reasoning and Acting) es un paradigma para el diseño de agentes de IA en el que un agente utiliza el razonamiento en cadena de pensamiento y las acciones de uso de herramientas en agregación.\n",
    "\n",
    "En lugar de generar una respuesta directa en un solo paso, un agente de ReAct piensa paso a paso y puede realizar acciones intermedias (como buscar algo o calcular un valor) antes de finalizar su respuesta.\n",
    "\n",
    "![Gráfico comparativo](imgs/comparativo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce525b94-08ae-45a5-8e59-1920fc28101d",
   "metadata": {},
   "source": [
    "## Ejemplo práctico 1: Un agente simple:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f819720f-698e-4d99-9c00-427ad6a3b99c",
   "metadata": {},
   "source": [
    "- Cargamos las librerías necesarias e inicializamos el LLM.\n",
    "- Es recomendable asignar el parámetro *temperatura* a 0 para que el LLM no sea muy creativo ya que se van a tener muchas herramientas a nuestra disposición y queremos que sea más determinista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d043000-793c-4648-83b2-64675a46ed50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate, SystemMessagePromptTemplate, ChatPromptTemplate, HumanMessagePromptTemplate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fac0759-6c7e-4489-87b9-e5a8802a418f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conexion con OpenAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "# Cargar archivo .env (busca automáticamente en el directorio actual o superiores)\n",
    "load_dotenv(find_dotenv(), override=True)\n",
    "\n",
    "# Verificar que la API key esté disponible\n",
    "if not os.getenv(\"OPENAI_API_KEY\"):\n",
    "    raise ValueError(\"!! No se encontró OPENAI_API_KEY en el .env ni en el entorno\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be95ed6-d82e-4e34-a7f1-766b27de34a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(\n",
    "    openai_api_key=os.getenv(\"OPENAI_API_KEY\"),   # sk-proj-...\n",
    "    model=\"gpt-4o\",\n",
    "    temperature=0.2,\n",
    ")\n",
    "\n",
    "print(chat.invoke(\"Hola, ¿cómo estás?, ¿quién eres?\").content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d718c973-078f-4ef7-b6ad-f69e2239d896",
   "metadata": {},
   "source": [
    "- Se importan las clases para usar los agentes:\n",
    "\n",
    "### `load_tools`\r\n",
    "Función para cargar herramientas predefinidas o personalizadas que los agentes pueden usar, como calculadoras, motores de búsqueda o APIs.\r\n",
    "\r\n",
    "### `initialize_agent`\r\n",
    "Configura un agente combinando un modelo de lenguaje (LLM), herramientas y un tipo de agente, ajustando su comportamiento para resolver tareas específicas.\r\n",
    "\r\n",
    "### `AgentType`\r\n",
    "Enumeración que define los diferentes tipos de agentes disponibles, como reactivos o conversacionales, permitiendo seleccionar el enfoque más adecuado.\r\n",
    "\r\n",
    "### `create_react_agent`\r\n",
    "Función que crea un agente basado en el marco ReAct, combinando razonamiento y acciones para resolver tareas de múltiples pasos.\r\n",
    "\r\n",
    "### `AgentExecutor`\r\n",
    "Clase que ejecuta las tareas del agente, gestionando el uso de herramientas y devolviendo resultados tras completar los objetivos.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13978673-1db8-41a6-8b7b-b1e89cb973f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import (load_tools,\n",
    "                            initialize_agent,\n",
    "                            AgentType,\n",
    "                            create_react_agent,\n",
    "                            AgentExecutor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca94f8a2-effa-4d65-9827-47262a625b6c",
   "metadata": {},
   "source": [
    "- Ahora se definen las herramientas a las cuales tendrá acceso el angente, a parte del propio LLM. Podemos ver un listado de tales herramientas en el siguiente enlace:  https://python.langchain.com/docs/integrations/tools/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84538b5-d49e-4665-b716-62450e470fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para usa esta Tool, es posible que debas instalar por consola:  pip install numexpr\n",
    "tools = load_tools([\"llm-math\",],llm=llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f26b52-a292-4de9-b6c5-1a303b7b3b06",
   "metadata": {},
   "source": [
    "- Se pueden ver todos los agentes disponibles para usar con la siguiente linea de código:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84b8374-2624-40bb-a974-206055034cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dir(AgentType) #Vemos los diferentes tipos de agente a usar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0fc02b6-c207-41c2-a4d7-60cca8cda3f1",
   "metadata": {},
   "source": [
    "- Describirmos brevemente aqui cada tipo:\n",
    "\n",
    "### `CHAT_CONVERSATIONAL_REACT_DESCRIPTION`\n",
    "Agente para interacciones conversacionales, combina razonamiento y respuestas basadas en el contexto del chat.\n",
    "\n",
    "### `CHAT_ZERO_SHOT_REACT_DESCRIPTION`\n",
    "Similar al anterior, pero actúa sin ejemplos previos, tomando decisiones en tiempo real.\n",
    "\n",
    "### `CONVERSATIONAL_REACT_DESCRIPTION`\n",
    "Enfocado en conversaciones, utiliza razonamiento y herramientas externas para responder con precisión.\n",
    "\n",
    "### `OPENAI_FUNCTIONS`\n",
    "Agente que utiliza funciones específicas de OpenAI para manejar tareas definidas por la API.\n",
    "\n",
    "### `OPENAI_MULTI_FUNCTIONS`\n",
    "Extensión del anterior, soporta múltiples funciones de OpenAI para tareas más complejas.\n",
    "\n",
    "### `REACT_DOCSTORE`\n",
    "Agente diseñado para buscar y extraer información en bases de datos documentales.\n",
    "\n",
    "### `SELF_ASK_WITH_SEARCH`\n",
    "Agente que formula preguntas a sí mismo y utiliza herramientas de búsqueda para encontrar respuestas.\n",
    "\n",
    "### `STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION`\n",
    "Agente conversacional que sigue un enfoque estructurado para tareas sin ejemplos previos.\n",
    "\n",
    "### `ZERO_SHOT_REACT_DESCRIPTION`\n",
    "Agente genérico que resuelve tareas en tiempo real, razonando y actuando sin datos de entrenamiento específicos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e796ea6f-8819-427d-b3d2-b5fb6ff4bc70",
   "metadata": {},
   "source": [
    "- Ahora se puede inicializar el agente y posteriormente incializar.\n",
    "\n",
    "***Tener en cuenta que es una versión que está en transcición y será obsoleta en futuras versiones. Estable hasta el momento.***\n",
    "\n",
    "- Se utiliza el Zero Shot porque no estamos dando ningún ejemplo, solo pidiendo al agente hacer una tarea sin ejemplos previos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b15b324-ade8-4b4a-8dca-ca011a2fd78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,verbose=True,handle_parsing_errors=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888b63b1-b18f-4db9-8067-987f681a17f0",
   "metadata": {},
   "source": [
    "- Ahora realizamos la solicitud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75770558-44fb-4943-96dd-84d3d20fe853",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.invoke(\"Cuánto es 2345 multiplicado por 5431 y después sumado 1234\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73ca7f2-fccd-4424-9622-6402ab689459",
   "metadata": {},
   "source": [
    "- Qué pasa si solo se lo pregunto al LLM ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0615993-afb4-4e72-ae2a-f2701509be83",
   "metadata": {},
   "outputs": [],
   "source": [
    "respuesta = llm.invoke(\"Cuánto es 2345 multiplicado por 5431 y después sumado 1234\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c398b8b-63ec-4e2d-ac37-be2fbc2399c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(respuesta.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35bbf002-44f6-4070-8b98-709d85bf29e3",
   "metadata": {},
   "source": [
    "## Ejemplo 2: Consulta a motores de búsqueda\n",
    "\n",
    "- En este ejemplo se realiza va a utilizar una Tools llamada SerpApi, la cual da acceso a múltiples motores de búsqueda, por ahora en forma gratuita.\n",
    "- Para utilizarla se debe crear una cuenta y obtener un \"ApiKey\" en forma similar como se hizo con OpenAI.\n",
    "- Se puede crear la cuenta en la siguiente URL: https://serpapi.com/\n",
    "- Se debe instalar por consola: *pip install google-search-results*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0ae486-2b7c-4378-85fb-aec999c3c222",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6ac9c2-42a0-4924-9623-46e2e348bb44",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('key/key_serpapi.txt')\n",
    "serp_api_key = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13136c46-4d98-4551-9401-0215cc3b9ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definir variable de entorno para que funcione correctamente:\n",
    "import os\n",
    "os.environ[\"SERPAPI_API_KEY\"]=serp_api_key #Si no está definida el error nos dará el nombre de la variable de entorno que espera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae60232-cd93-4d9a-9183-5358c9e40602",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(os.getenv(\"SERPAPI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63200ed-7bb1-4e9d-a555-51fd543fc3a5",
   "metadata": {},
   "source": [
    "- Se definen las herramientas a las que tendrá acceso el agente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb1472b-b622-4a62-812a-c37124c7a79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install google-search-results\n",
    "\n",
    "tools = load_tools([\"serpapi\",\"llm-math\",],llm=llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79922b8-2031-4167-b61a-701065c2567d",
   "metadata": {},
   "source": [
    "- Se inicializa el agente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c4db10-4e47-4bf9-a972-f49690525c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b03d7e-6859-45f2-b20b-af4823013f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.invoke(\"¿En qué año ganó su ultima Champions League el Real Madrid? ¿Cuál es el resultado de ese año multiplicado por 3?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45092b10-4e4b-427e-a40f-95b42fe23fc5",
   "metadata": {},
   "source": [
    "## Ejemplo 3. Un agente programador"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4782125-3fac-4f13-b06d-849fc3755e40",
   "metadata": {},
   "source": [
    "- En este ejemplo se utiliza una Tool especializada en generar código."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea5e39a-e19e-4be4-a4bc-65e55a2ee5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librerías requeridas\n",
    "#from langchain.prompts import PromptTemplate, SystemMessagePromptTemplate,ChatPromptTemplate, HumanMessagePromptTemplate\n",
    "#from langchain.agents import load_tools,initialize_agent,AgentType,create_react_agent,AgentExecutor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32da9985-ffda-4fe3-81ea-9f22c74c3cec",
   "metadata": {},
   "source": [
    "- Las clases requeridas para este ejemmplo particular:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c23855-334f-467c-9d1c-7f8a416570c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# puede requerir instalar desde consola: pip install langchain_experimental\n",
    "from langchain_experimental.agents.agent_toolkits import create_python_agent\n",
    "from langchain_experimental.tools.python.tool import PythonREPLTool\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a107a4-7ae9-4399-9790-5f4bc980a686",
   "metadata": {},
   "source": [
    "- `create_python_agent` Es una función de utilidad de LangChain que crea y configura un agente basado en lenguaje natural, capaz de usar herramientas para ejecutar código Python y razonar sobre los resultados.``\n",
    "- `PythonREPLTool` Es una herramienta (Tool) de LangChain que permite ejecutar código Python en un entorno REPL (Read-Eval-Print Loop)\n",
    "   - Toma un fragmento de código Python como entrada.\n",
    "   - Lo evalúa dentro de un entorno controlado.\n",
    "   - Devuelve el resultado o la salida como texto.\n",
    "   - Es útil para cálculos matemáticos, manipulación de listas, funciones, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8cfd6e9-6fcc-450e-bf4f-83f80946f067",
   "metadata": {},
   "source": [
    "- se crea el agente para crear y ejecutar código Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2cf1494-6f41-41fb-8c85-2b15fd36f2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_python_agent(tool=PythonREPLTool(),\n",
    "                           llm=llm,\n",
    "                           agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, \n",
    "                            verbose=True,\n",
    "                           handle_parsing_errors=True )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1080c226-71a3-43a5-be46-a75178f34d04",
   "metadata": {},
   "source": [
    "- Ejemplo de aplicacíón. Ordenar una lista dada:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55736a7d-0acc-4ed3-a52a-9df3ba2be309",
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_ejemplo = [3,1,5,3,5,6,7,3,5,10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57fd40a4-3962-46be-a408-6bd8b1db7e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.invoke('Ordena la lista dada {lista_ejemplo}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03d2112-78a3-40b3-ab7b-90484bbcb798",
   "metadata": {},
   "source": [
    "## Ejemplo 4. Agente con Tool personalizada"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a18f2b-96d6-4b0b-95f8-f88bfc3b65fb",
   "metadata": {},
   "source": [
    "- Es posible desarrollar nuestras propias Tools, para resolver problemas específicos, con software propio o de la empresa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07fa657-ab74-48b8-8028-7657306417fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importemos las librerias para el ejemplo\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate, SystemMessagePromptTemplate,ChatPromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain.agents import load_tools,initialize_agent,AgentType,create_react_agent,AgentExecutor\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a387d235-2715-4529-a108-9a1a99d4c7bc",
   "metadata": {},
   "source": [
    "### Un ejemplo sencillo, una herramienta propia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9215fad6-9a73-4297-8c4a-a7d5f17a4ace",
   "metadata": {},
   "source": [
    "- Se requiere importar la siguiente liberia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95eb0854-ff38-416c-9cd3-64fa7274eca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1e1951-b888-4347-be27-be25acfb5c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def persona_amable (text: str) -> str:\n",
    "    '''Retorna la persona más amable. Se espera que la entrada esté vacía \"\" \n",
    "    y retorna la persona más amable del universo'''\n",
    "    return \"Pepito Pérez\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17fc833e-9fde-4d30-8b7a-6256bbf16e3f",
   "metadata": {},
   "source": [
    "- Que pasa si invocamos al agente sin indicarle la tool especializada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a9ad49-bc1c-48bb-87a7-9f4a71ed7e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = load_tools([\"wikipedia\",\"llm-math\",],llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef11eb6-9197-4384-a495-ff91f259b7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e86520-5d21-4a45-bde4-4cc17faddbd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.invoke(\"¿Quién es la persona más amable del universo?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e25ffde-3a1d-4bb6-811d-89bf746c3db2",
   "metadata": {},
   "source": [
    "### Ejecutar el ejemplo utilizando la nueva tool personalizada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962b8e0c-74ab-43af-87d6-c5b4bfc40c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = tools + [persona_amable]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25cf059-7596-402b-841f-18e971619a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a22496b-729e-4e2c-b57f-1d3d971d10cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = agent.invoke(\"¿Quién es la persona más amable del universo?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e829b5fb-89c9-4a7e-a2f3-defc69678e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result['output'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39dbd07-d67c-431f-bd3b-e06a97dbaf84",
   "metadata": {},
   "source": [
    "### Una plantilla para una API interna\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70aa3ff3-db1e-49eb-93ec-8f2a9fadbff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def nombre_api_interna(text: str) -> str:\n",
    "    '''Conecta a la API_xx que realiza la tarea xx, debes usar esta API Key'''\n",
    "    ##Definir conexión a la API interna y devolver un resultado\n",
    "    return resultado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d5bccd-0883-462d-b484-1dba156abcbf",
   "metadata": {},
   "source": [
    "### Y si tratamos de consultar la hora actual al agente?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2439b740-3dee-433d-b19b-c0253a070f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solicitud con las herramientas actuales no proporciona el resultado que queremos\n",
    "agent.invoke(\"¿Cuál es la hora actual?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8f722a-fc9f-465b-bd88-661751e40f8e",
   "metadata": {},
   "source": [
    "### Tool personalizada para obtener la hora actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d53408-44c3-4b26-90ad-e2ff801cf331",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372053f3-3cf5-4367-b07a-d3abb4e6aef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def hora_actual(text: str)->str:\n",
    "    '''Retorna la hora actual, debes usar esta función para cualquier consulta sobre la hora actual. Para fechas que no sean\n",
    "    la hora actual, debes usar otra herramienta. La entrada está vacía y la salida retorna una string'''\n",
    "    return str(datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37691edc-7cfc-4082-a2b5-1adc7d041548",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = tools + [hora_actual]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863efd79-d467-4da7-9dcc-136a9d4cb6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a557d42b-2a79-4eba-9de5-ed6b17eac9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solicitud con las herramientas actuales SÍ proporciona el resultado que queremos\n",
    "resultado = agent.invoke(\"¿Cuál es la hora actual?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57e8391-f183-4b17-946b-58766f27cb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado['output']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e68c0e-6f44-4724-93a6-705702276b6d",
   "metadata": {},
   "source": [
    "## Ejemplo 5. Agentes con memoria"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82346ddc-c28c-40cd-b82f-09cc4c9d1a32",
   "metadata": {},
   "source": [
    "- En este ejemplo se revisa como se incorpora la memoria en una aplicación conversacional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04b4926-cbfd-4379-b8cb-7d517b54aee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se importan las liberias respectivas\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate, SystemMessagePromptTemplate,ChatPromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain.agents import load_tools,initialize_agent,AgentType,create_react_agent,AgentExecutor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374318fb-5c40-4694-b4cd-a1c252423d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604cd7b1-00d0-4360-92e3-8e0be632cfe4",
   "metadata": {},
   "source": [
    "- **En este caso se pone una clave o etiqueta a la memoria: *\"chat_history\"***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4d6186-27c5-4fa3-a4fe-5236b1cfd55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory(memory_key=\"chat_history\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3e87fe-b106-4cef-85e5-a0c0fb594b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = load_tools([\"wikipedia\",\"llm-math\",],llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3029a8f3-0b22-4ec6-8ffd-e9292c871563",
   "metadata": {},
   "outputs": [],
   "source": [
    "# agent = initialize_agent(tools, llm, agent=AgentType.CONVERSATIONAL_REACT_DESCRIPTION,memory=memory,verbose=True)\n",
    "\n",
    "agent = initialize_agent(\n",
    "    tools,\n",
    "    llm,\n",
    "    agent=AgentType.CONVERSATIONAL_REACT_DESCRIPTION,\n",
    "    memory=memory,\n",
    "    verbose=True,\n",
    "    handle_parsing_errors=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b812e12d-b1df-41dc-b859-0e12cc34e8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.invoke(\"Cual es el computador de alto rendimiento más poderoso en la actualidad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47fb5c1a-a932-493f-9162-b24e4e91ad06",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.invoke(\"¿Quien lo fabria y en que pais está ubicado?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0893a0-13ed-4291-9357-e941487effd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.invoke(\"¿Cuantos cores tiene?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a73926-f84c-4a1b-ba6d-618d08cfae51",
   "metadata": {},
   "source": [
    "## Ejemplo 6. El agente consulta una base de datos vectorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224dbe60-cf8c-4545-bf59-a11b183d0662",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liberias relacionadas\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate, SystemMessagePromptTemplate,ChatPromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain.agents import load_tools,initialize_agent,AgentType,create_react_agent,AgentExecutor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7dd9a4-6f1a-4a6f-965a-12f267c8ae6d",
   "metadata": {},
   "source": [
    "- Se debe cargar la base de datos vectorial y el compresor, como en los ejemplos anteriores. Tambien se va añadir memoria al agente.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d530157-72a3-4c7e-865e-d94d84cdb97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bddd346-7f57-4c58-a7ee-4c38a2f14704",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import SKLearnVectorStore\n",
    "\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "\n",
    "from langchain.retrievers.document_compressors import LLMChainExtractor\n",
    "\n",
    "import torch\n",
    "\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "# Detectar GPU si está disponible\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Instanciar LaBSE\n",
    "function_embedding = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/LaBSE\",\n",
    "    model_kwargs={\"device\": device},\n",
    "    encode_kwargs={\"normalize_embeddings\": True}\n",
    ")\n",
    "\n",
    "persist_path=\"ejemplosk_embedding_db\"  \n",
    "\n",
    "vector_store_connection = SKLearnVectorStore(embedding=function_embedding, persist_path=persist_path, serializer=\"parquet\")\n",
    "\n",
    "compressor = LLMChainExtractor.from_llm(llm)\n",
    "\n",
    "compression_retriever = ContextualCompressionRetriever(base_compressor=compressor, base_retriever=vector_store_connection.as_retriever())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c3bcb1-8c74-49ac-8f10-aa3f544d32ee",
   "metadata": {},
   "source": [
    "- A partir de la base de datos vectorial se construye la nueva tool, para obtener resultados optimos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44eed811-698b-434e-b3e6-0236580d33c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30dc3e8f-b9b8-4742-942c-fb65813e38d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def consulta_interna(text: str) -> str:\n",
    "    '''Retorna respuestas sobre el Reglamento Académico de Pregrado de la Universidad de Pamplona. \n",
    "    Se espera que la entrada sea una cadena de texto y retorna una cadena con el resultado más relevante. \n",
    "    Si la respuesta con esta herramienta es relevante, \n",
    "    no debes usar ninguna herramienta más ni tu propio conocimiento como LLM.'''\n",
    "    compressed_docs = compression_retriever.invoke(text)\n",
    "    \n",
    "    if not compressed_docs:\n",
    "        return \"No se encontró información relevante sobre esa consulta en el reglamento académico.\"\n",
    "    \n",
    "    resultado = compressed_docs[0].page_content\n",
    "    return resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc75d9e-db28-49c6-b08a-35bcd5ab8cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = load_tools([\"wikipedia\",\"llm-math\"],llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4c3f80-dbf6-4a8d-8a3e-7f4ae4715d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools=tools+[consulta_interna]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a15b25-7697-4dc0-b638-c11926c78e34",
   "metadata": {},
   "source": [
    "- Ahora se crea y ejecuta el agente conversacional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300cd887-d1b0-4baa-8d0b-5da5ab01d88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = initialize_agent(tools, llm, \n",
    "                         agent=AgentType.CONVERSATIONAL_REACT_DESCRIPTION,\n",
    "                         memory=memory,\n",
    "                         handle_parsing_errors=True,\n",
    "                         verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f74d58-141f-499d-8918-d62a6e5914e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.invoke(\"¿Qué universidades existen en Norte de Santander, Colombia? Responde en español\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15e5fdd-de3b-4eba-9aee-e2cbbac3f76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.invoke(\"¿Cuáles son los requisitos de admisión para la Universidad de Pamplona?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30cbb9ef-44d4-4925-82ab-513d6003f1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.invoke(\"¿Cómo puedo cancelar materias en dicha universidad?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b008fd0-fd69-48ba-bd54-1b72db086067",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11f9ca1-353a-48b3-8a70-1c12ffb600fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (lang-env)",
   "language": "python",
   "name": "lang-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
